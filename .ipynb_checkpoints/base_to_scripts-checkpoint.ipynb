{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "from reskit.core import DataTransformer, MatrixTransformer, Pipeliner\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "import parsimony.estimators as estimators\n",
    "import parsimony.functions.nesterov.tv as tv_helper\n",
    "\n",
    "from data_load import load_meshes_coor_tria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_load import load_meshes_coor_tria\n",
    "import parsimony.functions.nesterov.tv as tv_helper\n",
    "import parsimony.estimators as estimators\n",
    "import pickle\n",
    "import numpy as np\n",
    "path_meshes = '/home/bgutman/datasets/HCP/'\n",
    "mesh_coord, mesh_triangles = load_meshes_coor_tria(path_meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = tv_helper.linear_operator_from_mesh(mesh_coord, mesh_triangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = 0.1  # l1 penalty\n",
    "l2 = 0.1  # l2 penalty\n",
    "tv = 0.1  # tv penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data = \"/cobrain/groups/ml_group/data/HCP/cleaned_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path_data + \"normed_connectomes\", 'rb') as f:\n",
    "    Y = pickle.load(f)\n",
    "    \n",
    "with open(path_data + \"subjects_log_jac\", 'rb') as f:\n",
    "    log_jac = pickle.load(f)\n",
    "with open(path_data + \"subjects_thinkness\", 'rb') as f:\n",
    "    thinkness = pickle.load(f)\n",
    "with open(path_data + \"subjects_mesh_area\", 'rb') as f:\n",
    "    mesh_area = pickle.load(f)\n",
    "with open(path_data + \"subjects_roi_thinkness\", 'rb') as f:\n",
    "    roi_thinkness = pickle.load(f)\n",
    "with open(path_data + \"subjects_roi_volume\", 'rb') as f:\n",
    "    roi_volume = pickle.load(f)\n",
    "with open(path_data + \"mean_mesh_labels\", 'rb') as f:\n",
    "    mean_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nodes_attribute(think, log_jacs, meshes_area, mean_labels, node1, node2 = None):\n",
    "    '''\n",
    "    think, log_jac, meshes_atra -- some type of data corresponding to meshes\n",
    "    mean_labels - mapping of each mesh to node \n",
    "    \n",
    "    node1 - integer from 1 to 70, except 4, 39\n",
    "    node2 - integer from 1 to 70, except 4, 39\n",
    "    \n",
    "    '''\n",
    "    X = []\n",
    "    un_label = np.array(list(mean_labels[0]) + list(mean_labels[1]))\n",
    "    idx1 = np.where(un_label == node1)[0]\n",
    "    if node2 != None:\n",
    "        idx2 = np.where(un_label == node2)[0]\n",
    "    \n",
    "    for l, one in enumerate(think):\n",
    "#         if l%100 == 0:\n",
    "# #             print(l)\n",
    "#         one_think = np.array(list(one[0]) + list(one[1]))\n",
    "#         one_log_jac = np.array(list(log_jacs[l][0]) + list(log_jacs[l][1]))\n",
    "#         one_mesh_area = np.array(list(meshes_area[l][0]) + list(meshes_area[l][1]))\n",
    "        one_think = one\n",
    "        one_log_jac = log_jacs[l]\n",
    "        one_mesh_area = meshes_area[l]\n",
    "        \n",
    "        node_think1 = one_think[idx1]\n",
    "    \n",
    "        node_log_jac1 = one_log_jac[idx1]\n",
    "    \n",
    "        node_mesh_area1 = one_mesh_area[idx1]\n",
    "        if node2!= None:\n",
    "            node_think2 = one_think[idx2]\n",
    "\n",
    "            node_log_jac2 = one_log_jac[idx2]\n",
    "\n",
    "            node_mesh_area2 = one_mesh_area[idx2]\n",
    "\n",
    "            x = np.concatenate([node_think1, node_think2, node_log_jac1, node_log_jac2,\n",
    "                            node_mesh_area1, node_mesh_area2])\n",
    "        else:\n",
    "            x = np.concatenate([node_think1, node_log_jac1,node_mesh_area1])\n",
    "        X += [x]\n",
    "        \n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_meshes_coord_tria(tria, mean_labels, node1, node2 = None, coord = None):\n",
    "    '''\n",
    "    tria - (number of triangles of mesh, 3) \n",
    "    mean_labels - mapping of each mesh to node \n",
    "    node1 - integer from 1 to 70, except 4, 39\n",
    "    node2 - integer from 1 to 70, except 4, 39\n",
    "    \n",
    "    coord - if needed\n",
    "    \n",
    "    '''\n",
    "    node_tria = []\n",
    "    \n",
    "    un_label = np.array(list(mean_labels[0]) + list(mean_labels[1]))\n",
    "    idx1 = np.where(un_label == node1)[0]\n",
    "    meshes = set(idx1)\n",
    "    if coord != None:\n",
    "        node_coord = coord[idx1, :]\n",
    "    if node2 != None:\n",
    "        idx2 = np.where(un_label == node2)[0]\n",
    "        if coord != None:\n",
    "            node_coord = np.concatenate([node_coord,coord[idx2,:]])\n",
    "        meshes.update(idx2)\n",
    "    \n",
    "    for l, one in enumerate(tria):\n",
    "        if len(meshes.intersection(set(one))) == 3:\n",
    "            node_tria += [one]\n",
    "    if coord != None:\n",
    "        return np.array(node_tria), node_coord\n",
    "    else:\n",
    "        return np.array(node_tria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_nodes_attribute(thinkness.reshape(n_sample,-1), log_jac.reshape(n_sample,-1), mesh_area.reshape(n_sample,-1), mean_labels, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = 0.1  # l1 penaltya\n",
    "l2 = 0.1  # l2 penalty\n",
    "tv = 0.1  # tv penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node1_A = tv_helper.linear_operator_from_mesh(mesh_coord, node1_tria)\n",
    "A, n_com = tv_helper.linear_operator_from_shape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(789, 1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = Y[:, 1, 2].reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((789, 10437),)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<327684x327684 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5714 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(node1_A)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvenet_estimator = estimators.LinearRegressionL2SmoothedL1TV(l1=l1, l2=l2, tv=tv, A= node1_A)\n",
    "#tvenet_estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'l1': [1e-7, 1e-3, 0.1, 0.5, 1, 10, 100],\n",
    "    \n",
    "    'l2': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "    \n",
    "    'tv': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "    \n",
    "    'penalty_start': [0,10,100,1000,10000],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsimony.estimators.LinearRegressionL2SmoothedL1TV at 0x7fe7afcfc550>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators.LinearRegressionL2SmoothedL1TV(l1=1, l2=1, tv=1, A = node1_A,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,  y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from parsimony.estimators import GridSearchKFoldRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsR = GridSearchKFoldRegression(tvenet_estimator, params, score_function=mean_squared_error, K = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K': 5,\n",
       " 'estimator': <parsimony.estimators.LinearRegressionL2SmoothedL1TV at 0x7fe7ad915588>,\n",
       " 'grid': {'deep': [True],\n",
       "  'l1': [1e-07, 0.001, 0.1, 0.5, 1, 10, 100],\n",
       "  'l2': [1e-07, 0.001, 0.1, 0.5, 1, 10, 100],\n",
       "  'tv': [1e-07, 0.001, 0.1, 0.5, 1, 10, 100]},\n",
       " 'maximise': True,\n",
       " 'score_function': <function sklearn.metrics.regression.mean_squared_error>}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsR.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from reskit.core import DataTransformer, MatrixTransformer, Pipeliner\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomStandardScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,):\n",
    "        self.f = 0\n",
    "    def fit(self, X, y = None):\n",
    "        self.StandardScaler = StandardScaler()\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        keys = ['think', 'log_jac', 'mesh_area',]\n",
    "        for k in keys:\n",
    "            print(X[k].shape, k)\n",
    "            X[k] = self.StandardScaler.fit_transform(X[k])\n",
    "        return X\n",
    "class CustomMinMaxScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,):\n",
    "        self.f = 0\n",
    "    def fit(self, X, y = None):\n",
    "        self.MinMaxScaler = MinMaxScaler()\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        keys = ['think', 'log_jac', 'mesh_area',]\n",
    "        for k in keys:\n",
    "            X[k] = self.MinMaxScaler.fit_transform(X[k])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NodeAndNodeToEdge(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, node1, node2 = None):\n",
    "        assert node1 != node2, 'You can find edge between node and itself'\n",
    "        self.node1 = node1\n",
    "        self.node2 = node2\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y):\n",
    "        data = get_nodes_attribute(X['think'], X['log_jac'], X['mesh_area'], X['mean_labels'], self.node1, self.node2)\n",
    "        new_tria = get_meshes_coord_tria(X['mesh_coord'], X['mesh_triangles'], X['mean_labels'], self.node1, self.node2)\n",
    "        A = tv_helper.linear_operator_from_mesh(X['mesh_coord'], new_tria)\n",
    "        new_X = {}\n",
    "        new_X['data'] = data\n",
    "        new_X['A'] = A\n",
    "        new_y = y[:,node1, node2]\n",
    "        \n",
    "        return new_X, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVMethod(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, l1=1, l2=1, tv=1):\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.tv = tv\n",
    "        self.A = np.zeros((2,2))\n",
    "    def fit(self, X, y):\n",
    "        self.A = X['A']\n",
    "        self.estimator = estimators.LinearRegressionL2SmoothedL1TV(l1 = self.l1, l2 = self.l2, tv = self.tv, A = X['A'])\n",
    "        self.estimator.fit(X['data'], y)\n",
    "        return self\n",
    "    def get_params(self, deep = True):\n",
    "        return {'l1': self.l1, 'l2':self.l2, 'tv':self.tv, 'A': self.A}\n",
    "        \n",
    "    def set_params(self, **param):\n",
    "        for k, v in param.items():\n",
    "            setattr(self, k, v) \n",
    "        return self\n",
    "    def get_score(self, X, y):\n",
    "        return self.score(X['data'], y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [('StandardScaler', CustomStandardScaler()),\n",
    "           ('MinMaxScaler', CustomMinMaxScaler())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [('NodesToEdge', NodeAndNodeToEdge(1,2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method = [('LinearRegTV', TVMethod(0.1,0.1,0.1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid ={'LinearRegTV': {'l1': [1e-7, 1e-3, 0.1, 0.5, 1, 10, 100],\n",
    "    \n",
    "                             'l2': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "    \n",
    "                             'tv': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "    \n",
    "                             'penalty_start': [0,10,100,1000,10000],\n",
    "                             \n",
    "                             'A': [1,2,3]},\n",
    "             \n",
    "             'features': {'node1':[1,2,3],\n",
    "                         'node2': [4,5,6]}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'l1': [1e-7, 1e-3, 0.1, 0.5, 1, 10, 100],\n",
    "    \n",
    "    'l2': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "    \n",
    "    'tv': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "    \n",
    "    'penalty_start': [0,10,100,1000,10000],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = [('scalers', scalers),\n",
    "         ('features', features),\n",
    "        ('ml_method', method)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchKFoldRegression(tvenet_estimator, params, score_function=mean_squared_error, K = 10)\n",
    "eval_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeliner = Pipeliner(steps=steps, grid_cv=grid_cv, \n",
    "                    eval_cv = eval_cv, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scalers</th>\n",
       "      <th>features</th>\n",
       "      <th>ml_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>NodesToEdge</td>\n",
       "      <td>LinearRegTV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>NodesToEdge</td>\n",
       "      <td>LinearRegTV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          scalers     features    ml_method\n",
       "0  StandardScaler  NodesToEdge  LinearRegTV\n",
       "1    MinMaxScaler  NodesToEdge  LinearRegTV"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeliner.plan_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = X.shape[0]\n",
    "new_X = {}\n",
    "new_X['think'] = thinkness.reshape(n_sample, -1)\n",
    "new_X['log_jac'] = log_jac.reshape(n_sample, -1)\n",
    "new_X['mesh_area'] = mesh_area.reshape(n_sample, -1) \n",
    "new_X['mean_labels'] = mean_labels\n",
    "new_X['mesh_coord'] = mesh_coord \n",
    "new_X['mesh_triangles'] = mesh_triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: 1/2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-341-a0c519e77052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeliner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_square_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'scalers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tv.log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/reskit/core.py\u001b[0m in \u001b[0;36mget_results\u001b[0;34m(self, X, y, caching_steps, scoring, logs_file, collect_n)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mtime_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mX_featured\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_with_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0mspent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Got Features: {} sec\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspent_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/reskit/core.py\u001b[0m in \u001b[0;36mtransform_with_caching\u001b[0;34m(self, X, y, row_keys)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mrow_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mtransform_X_from_last_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mlast_cached_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/reskit/core.py\u001b[0m in \u001b[0;36mtransform_X_from_last_cached\u001b[0;34m(row_keys, columns)\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mprev_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "table = pipeliner.get_results(new_X, y, scoring=['mean_square_error'], caching_steps = ['scalers', 'features'], logs_file = 'tv.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
