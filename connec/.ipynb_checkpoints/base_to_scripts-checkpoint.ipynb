{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "from utils import get_nodes_attribute\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import RandomizedSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "\n",
    "\n",
    "path_data = \"/nmnt/x01-hdd/HCP/data/\"\n",
    "\n",
    "with open(path_data + \"mean_mesh_labels\", 'rb') as f:\n",
    "    mean_labels = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"normed_connectomes\", 'rb') as f:\n",
    "    Y = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_log_jac\", 'rb') as f:\n",
    "    log_jac = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_thinkness\", 'rb') as f:\n",
    "    thinkness = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_mesh_area\", 'rb') as f:\n",
    "    mesh_area = pickle.load(f)\n",
    "\n",
    "\n",
    "    \n",
    "thinkness = thinkness.reshape(789,-1)\n",
    "log_jac = log_jac.reshape(789,-1)\n",
    "mesh_area = mesh_area.reshape(789,-1)\n",
    "\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "elastic_param = {'alpha': [1e-10, 1e-7, 1e-5, 1e-3, 0.1, 1.0, 5, 10, 20, 50, 70, 100,], \n",
    "                  'l1_ratio': [1e-10, 1e-7, 1e-3, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_res = '/nmnt/x03-hdd/HCP/'\n",
    "\n",
    "for i in range(1,70):\n",
    "        for j in range(i+1,70):\n",
    "            if i!=4 and i!=39:\n",
    "                print(i,j)\n",
    "                if np.sum(Y[:,i,j]) != 0:\n",
    "                \n",
    "\n",
    "                    \n",
    "                    X = get_nodes_attribute(thinkness, log_jac, mesh_area, mean_labels, i, j)\n",
    "                    \n",
    "                    elastic = ElasticNet()\n",
    "                    StanS = StandardScaler()\n",
    "                    MinM = MinMaxScaler()\n",
    "                    cv = ShuffleSplit(test_size=0.2)\n",
    "                    rg = RandomizedSearchCV(elastic, elastic_param, scoring = 'r2', \n",
    "                                            n_jobs=-1, cv = 10)\n",
    "                    \n",
    "                    rg.fit(X, Y[:,i,j])\n",
    "                    orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "                    orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "                    \n",
    "                    rg.fit(StanS.fit_transform(X), Y[:,i,j])\n",
    "                    st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "                    st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "                    \n",
    "                    rg.fit(MinM.fit_transform(X), Y[:,i,j])\n",
    "                    mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "                    mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "                    \n",
    "                    name_dir = 'exper_elastic_nodes_to_edge'\n",
    "                    edge = '/edge[' + str(i) + ',' + str(j) + ']'\n",
    "                    if not os.path.exists(path_res + name_dir):\n",
    "                        os.mkdir(path_res + name_dir)\n",
    "\n",
    "                    if not os.path.exists(path_res + name_dir + edge):\n",
    "                        os.mkdir(path_res + name_dir + edge)\n",
    "                    orig.to_csv(path_res + name_dir + edge +'/results_orig')\n",
    "                    st.to_csv(path_res + name_dir + edge + '/results_st')\n",
    "                    mm.to_csv(path_res + name_dir + edge + '/results_mm')\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.121983</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>-0.068455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_iter': 100, 'alpha': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.062698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008478</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.150589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.121983         0.002602        -0.068455               0.0   \n",
       "\n",
       "  param_alpha param_max_iter                         params  rank_test_score  \\\n",
       "0           1            100  {'max_iter': 100, 'alpha': 1}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score       ...         split7_test_score  \\\n",
       "0          -0.062698                 0.0       ...                 -0.033085   \n",
       "\n",
       "   split7_train_score  split8_test_score  split8_train_score  \\\n",
       "0                 0.0          -0.009529                 0.0   \n",
       "\n",
       "   split9_test_score  split9_train_score  std_fit_time  std_score_time  \\\n",
       "0          -0.001007                 0.0      0.008478        0.001759   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.150589              0.0  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.11202</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>-0.068455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_iter': 100, 'alpha': 10}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.062698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010132</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.150589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.11202         0.001784        -0.068455               0.0   \n",
       "\n",
       "  param_alpha param_max_iter                          params  rank_test_score  \\\n",
       "0          10            100  {'max_iter': 100, 'alpha': 10}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score       ...         split7_test_score  \\\n",
       "0          -0.062698                 0.0       ...                 -0.033085   \n",
       "\n",
       "   split7_train_score  split8_test_score  split8_train_score  \\\n",
       "0                 0.0          -0.009529                 0.0   \n",
       "\n",
       "   split9_test_score  split9_train_score  std_fit_time  std_score_time  \\\n",
       "0          -0.001007                 0.0      0.010132        0.001001   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.150589              0.0  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>-0.068455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_iter': 10, 'alpha': 10}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.062698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008863</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.150589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.108446         0.002167        -0.068455               0.0   \n",
       "\n",
       "  param_alpha param_max_iter                         params  rank_test_score  \\\n",
       "0          10             10  {'max_iter': 10, 'alpha': 10}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score       ...         split7_test_score  \\\n",
       "0          -0.062698                 0.0       ...                 -0.033085   \n",
       "\n",
       "   split7_train_score  split8_test_score  split8_train_score  \\\n",
       "0                 0.0          -0.009529                 0.0   \n",
       "\n",
       "   split9_test_score  split9_train_score  std_fit_time  std_score_time  \\\n",
       "0          -0.001007                 0.0      0.008863        0.001192   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.150589              0.0  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PLSRegression(copy=True, max_iter=500, n_components=2, scale=True, tol=1e-06)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "PLSRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "from utils import get_nodes_attribute\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, ShuffleSplit\n",
    "\n",
    "\n",
    "\n",
    "path_data = \"../\"\n",
    "\n",
    "with open(path_data + \"mean_mesh_labels\", 'rb') as f:\n",
    "    mean_labels = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"normed_connectomes\", 'rb') as f:\n",
    "    Y = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_log_jac\", 'rb') as f:\n",
    "    log_jac = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_thinkness\", 'rb') as f:\n",
    "    thinkness = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_mesh_area\", 'rb') as f:\n",
    "    mesh_area = pickle.load(f)\n",
    "\n",
    "\n",
    "    \n",
    "thinkness = thinkness.reshape(789,-1)\n",
    "log_jac = log_jac.reshape(789,-1)\n",
    "mesh_area = mesh_area.reshape(789,-1)\n",
    "\n",
    "\n",
    "\n",
    "plsr_param = {'n_components':[2,3,5],\n",
    "              'max_iter':[10, 100,500, 1000]}\n",
    "\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "\n",
    "\n",
    "for i in range(1,70):\n",
    "        for j in range(i+1,70):\n",
    "            if i!=4 and i!=39:\n",
    "                print(i,j)\n",
    "                if np.sum(Y[:,i,j]) != 0:\n",
    "                \n",
    "\n",
    "                    \n",
    "                    X = get_nodes_attribute(thinkness, log_jac, mesh_area, mean_labels, i, j)\n",
    "                    \n",
    "                    plsr = PLSRegression()\n",
    "                    StanS = StandardScaler()\n",
    "                    MinM = MinMaxScaler()\n",
    "                    cv = ShuffleSplit(test_size=0.2)\n",
    "                    rg = RandomizedSearchCV(plsr, plsr_param, scoring = 'r2', \n",
    "                                            n_jobs=1, cv = 10)\n",
    "                    \n",
    "                    rg.fit(X, Y[:,i,j])\n",
    "                    orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "                    orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "                    \n",
    "                    rg.fit(StanS.fit_transform(X), Y[:,i,j])\n",
    "                    st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "                    st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "                    \n",
    "                    rg.fit(MinM.fit_transform(X), Y[:,i,j])\n",
    "                    mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "                    mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "                    \n",
    "                    name_dir = 'exper_plsr_nodes_to_edge'\n",
    "                    edge = '/edge[' + str(i) + ',' + str(j) + ']'\n",
    "                    if not os.path.exists(name_dir):\n",
    "                        os.mkdir(name_dir)\n",
    "\n",
    "                    if not os.path.exists(name_dir + edge):\n",
    "                        os.mkdir(name_dir + edge)\n",
    "                    orig.to_csv(name_dir + edge +'/results_orig')\n",
    "                    st.to_csv(name_dir + edge + '/results_st')\n",
    "                    mm.to_csv(name_dir + edge + '/results_mm')\n",
    "                    break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_n_components</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239816</td>\n",
       "      <td>0.014399</td>\n",
       "      <td>-0.538829</td>\n",
       "      <td>0.095647</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_components': 2, 'max_iter': 1000}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.951549</td>\n",
       "      <td>0.09851</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482668</td>\n",
       "      <td>0.095658</td>\n",
       "      <td>-0.005524</td>\n",
       "      <td>0.08224</td>\n",
       "      <td>-0.178707</td>\n",
       "      <td>0.097014</td>\n",
       "      <td>0.009398</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.630246</td>\n",
       "      <td>0.005326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.239816         0.014399        -0.538829          0.095647   \n",
       "\n",
       "  param_max_iter param_n_components                                 params  \\\n",
       "0           1000                  2  {'n_components': 2, 'max_iter': 1000}   \n",
       "\n",
       "   rank_test_score  split0_test_score  split0_train_score       ...         \\\n",
       "0                1          -0.951549             0.09851       ...          \n",
       "\n",
       "   split7_test_score  split7_train_score  split8_test_score  \\\n",
       "0          -0.482668            0.095658          -0.005524   \n",
       "\n",
       "   split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
       "0             0.08224          -0.178707            0.097014      0.009398   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.001638        0.630246         0.005326  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_cmd_cobrain.py python some_script.py -c 8 -r 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/parsimony/config.py:55: RuntimeWarning: Could not locate the config file.\n",
      "  warnings.warn(\"Could not locate the config file.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "from parsimony.estimators import LinearRegressionL2SmoothedL1TV\n",
    "from parsimony.functions.nesterov.tv import linear_operator_from_mesh\n",
    "from parsimony.estimators import GridSearchKFoldRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data_load import load_meshes_coor_tria\n",
    "from utils import get_meshes_coord_tria, get_nodes_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_meshes = '../'\n",
    "\n",
    "mesh_coord, mesh_triangles = load_meshes_coor_tria(path_meshes)\n",
    "\n",
    "path_data = \"../\"\n",
    "\n",
    "with open(path_data + \"mean_mesh_labels\", 'rb') as f:\n",
    "    mean_labels = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"normed_connectomes\", 'rb') as f:\n",
    "    Y = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_log_jac\", 'rb') as f:\n",
    "    log_jac = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_thinkness\", 'rb') as f:\n",
    "    thinkness = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_mesh_area\", 'rb') as f:\n",
    "    mesh_area = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X\n",
    "st = StandardScaler()\n",
    "new_X = st.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-45096c20959e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mthinkness\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mStanS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthinkness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlog_jac\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mStanS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_jac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmesh_area\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mStanS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \"\"\"\n\u001b[1;32m    611\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[0;32m--> 612\u001b[0;31m                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                       force_all_finite)\n\u001b[1;32m    401\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "thinkness =  StanS.fit_transform(thinkness)\n",
    "log_jac =  StanS.fit_transform(log_jac)\n",
    "mesh_area =  StanS.fit_transform(mesh_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StanS = StandardScaler()\n",
    "St_think =  StanS.fit_transform(thinkness)\n",
    "St_log_jac =  StanS.fit_transform(log_jac)\n",
    "St_mesh_area =  StanS.fit_transform(mesh_area)\n",
    "\n",
    "MinM = MinMaxScaler()\n",
    "MinM_think =  MinM.fit_transform(thinkness)\n",
    "MinM_log_jac =  MinM.fit_transform(log_jac)\n",
    "MinM_mesh_area =  MinM.fit_transform(mesh_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thinkness = thinkness.reshape(789,-1)\n",
    "log_jac = log_jac.reshape(789,-1)\n",
    "mesh_area = mesh_area.reshape(789,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid ={'l1': [1e-7, 1e-3, 0.1, 0.5, 1, 10, 100],\n",
    "    \n",
    "             'l2': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "\n",
    "             'tv': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "\n",
    "             'penalty_start': [0,10,100,1000,10000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = linear_operator_from_mesh(mesh_coord, mesh_triangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import parsimony.functions.nesterov.l1tv as l1tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_tria = get_meshes_coord_tria(mesh_triangles, mean_labels, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = linear_operator_from_mesh(mesh_coord, new_tria)\n",
    "B = l1tv.linear_operator_from_mesh(mesh_coord, new_tria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, ShuffleSplit\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso_param = {'alpha':[0.1, 1, 10,4000],\n",
    "              'max_iter':[10, 100, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = make_regression()\n",
    "cv = ShuffleSplit(test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(lasso, lasso_param, scoring=make_scorer(r2_score), cv = cv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=0.33, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [0.1, 1, 10, 4000], 'max_iter': [10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(r2_score), verbose=0)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rg = RandomizedSearchCV(lasso, lasso_param, scoring = make_scorer(r2_score), \n",
    "#                                             n_jobs=1, cv = cv, refit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rg = RandomizedSearchCV(lasso, lasso_param, scoring = {'MSE':make_scorer(mean_squared_error),\n",
    "#                                                        'AE':make_scorer(mean_absolute_error),\n",
    "#                                                        'r2':make_scorer(r2_score)}, \n",
    "#                                             n_jobs=1, cv = cv, refit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ayagoz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=0.33, train_size=None),\n",
       "          error_score='raise',\n",
       "          estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'alpha': [0.1, 1, 10, 4000], 'max_iter': [10, 100, 1000]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=False,\n",
       "          return_train_score=True, scoring=make_scorer(r2_score),\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 0.1, 'max_iter': 1000}, 0.99999462739375733)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg.best_params_, rg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('try')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,70):\n",
    "        for j in range(i+1,70):\n",
    "            if i!=4 and i!=39:\n",
    "                print(i,j)\n",
    "                if np.sum(Y[:,i,j]) != 0:\n",
    "                \n",
    "                    #new_tria = get_meshes_coord_tria(mesh_triangles, mean_labels, i, j)\n",
    "                    #A = linear_operator_from_mesh(mesh_coord, new_tria)\n",
    "                    #print(len(A))\n",
    "                    \n",
    "                    X = get_nodes_attribute(thinkness, log_jac, mesh_area, mean_labels, i, j)\n",
    "                    \n",
    "                    lasso = Lasso()\n",
    "                    cv = ShuffleSplit(test_size=0.2)\n",
    "                    rg = RandomizedSearchCV(lasso, lasso_param, scoring = make_scorer(r2_score), \n",
    "                                            n_jobs=1, cv = 10)\n",
    "                    \n",
    "                    rg.fit(X, Y[:,i,j])\n",
    "                    data = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "                    data = data.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "                    \n",
    "\n",
    "                    \n",
    "                    name_dir = 'exper_lasso_nodes_to_edge'\n",
    "                    edge = '/edge[' + str(i) + ',' + str(j) + ']'\n",
    "                    if not os.path.exists(name_dir):\n",
    "                        os.mkdir(name_dir)\n",
    "\n",
    "                    if not os.path.exists(name_dir + edge):\n",
    "                        os.mkdir(name_dir + edge)\n",
    "                    data.to_csv(name_dir + edge +'/results')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15834</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>-0.068455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_iter': 10, 'alpha': 10}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.062698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.150589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.15834         0.001125        -0.068455               0.0   \n",
       "\n",
       "  param_alpha param_max_iter                         params  rank_test_score  \\\n",
       "0          10             10  {'max_iter': 10, 'alpha': 10}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score       ...         split7_test_score  \\\n",
       "0          -0.062698                 0.0       ...                 -0.033085   \n",
       "\n",
       "   split7_train_score  split8_test_score  split8_train_score  \\\n",
       "0                 0.0          -0.009529                 0.0   \n",
       "\n",
       "   split9_test_score  split9_train_score  std_fit_time  std_score_time  \\\n",
       "0          -0.001007                 0.0      0.002646        0.000047   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.150589              0.0  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_st = []\n",
    "best_params_st = []\n",
    "score_mm = []\n",
    "best_params_mm = []\n",
    "for i in range(1,70):\n",
    "        for j in range(i,70):\n",
    "            if i!=4 and i!=39:\n",
    "                if np.sum(y[:,i,j])! = 0:\n",
    "                \n",
    "                    new_tria = get_meshes_coord_tria(mesh_triangles, mean_labels, i, j)\n",
    "                    A = tv_helper.linear_operator_from_mesh(mesh_coord, new_tria)\n",
    "\n",
    "                    X = get_nodes_attribute(St_think, St_log_jac,St_mesh_area, mean_labels, i, j)\n",
    "                    tvenet_estimator = estimators.LinearRegressionL2SmoothedL1TV(l1=0., l2=0., tv=0., A = A)\n",
    "                    GridSearch = GridSearchKFoldRegression(tvenet_estimator, param_grid, maximise=False, K = 10)\n",
    "                    GridSearch.fit(X, y[:,i, j])\n",
    "                    score_st += [GridSearch._best_results]\n",
    "                    best_params_st += [GridSearch._best_params]\n",
    "\n",
    "\n",
    "\n",
    "                    X = get_nodes_attribute(MinM_think, MinM_log_jac, MinM_mesh_area, mean_labels, i, j)\n",
    "\n",
    "                    tvenet_estimator = estimators.LinearRegressionL2SmoothedL1TV(l1=0.1, l2=0.1, tv=0.1, A = A)\n",
    "                    GridSearch = GridSearchKFoldRegression(tvenet_estimator, param_grid,maximise=False, K = 10)\n",
    "                    GridSearch.fit(X, y[:,i, j])\n",
    "                    score_mm += [GridSearch._best_results]\n",
    "                    best_params_mm += [GridSearch._best_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path_meshes = '/home/bgutman/datasets/HCP/'\n",
    "\n",
    "# mesh_coord, mesh_triangles = load_meshes_coor_tria(path_meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path_data = \"/cobrain/groups/ml_group/data/HCP/cleaned_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path_data + \"normed_connectomes\", 'rb') as f:\n",
    "    Y = pickle.load(f)\n",
    "with open(path_data + \"subjects_log_jac\", 'rb') as f:\n",
    "    log_jac = pickle.load(f)\n",
    "with open(path_data + \"subjects_thinkness\", 'rb') as f:\n",
    "    thinkness = pickle.load(f)\n",
    "with open(path_data + \"subjects_mesh_area\", 'rb') as f:\n",
    "    mesh_area = pickle.load(f)\n",
    "with open(path_data + \"subjects_roi_thinkness\", 'rb') as f:\n",
    "    roi_thinkness = pickle.load(f)\n",
    "with open(path_data + \"subjects_roi_volume\", 'rb') as f:\n",
    "    roi_volume = pickle.load(f)\n",
    "with open(path_data + \"mean_mesh_labels\", 'rb') as f:\n",
    "    mean_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid ={'l1': [1e-7, 1e-3, 0.1, 0.5, 1, 10, 100],\n",
    "    \n",
    "             'l2': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "\n",
    "             'tv': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "\n",
    "             'penalty_start': [0,10,100,1000,10000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StanS = StandardScaler()\n",
    "St_think =  StanS.fit_transform(thinkness)\n",
    "St_log_jac =  StanS.fit_transform(log_jac)\n",
    "St_mesh_area =  StanS.fit_transform(mesh_area)\n",
    "\n",
    "MinM = MinMaxScaler()\n",
    "MinM_think =  MinM.fit_transform(thinkness)\n",
    "MinM_log_jac =  MinM.fit_transform(log_jac)\n",
    "MinM_mesh_area =  MinM.fit_transform(mesh_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_st = []\n",
    "best_params_st = []\n",
    "score_mm = []\n",
    "best_params_mm = []\n",
    "for i in range(1,70):\n",
    "        for j in range(i,70):\n",
    "            if i!=4 and i!=39:\n",
    "                if np.sum(y[:,i,j])! = 0:\n",
    "                \n",
    "                    new_tria = get_meshes_coord_tria(mesh_triangles, mean_labels, i, j)\n",
    "                    A = tv_helper.linear_operator_from_mesh(mesh_coord, new_tria)\n",
    "\n",
    "                    X = get_nodes_attribute(St_think, St_log_jac,St_mesh_area, mean_labels, i, j)\n",
    "                    tvenet_estimator = estimators.LinearRegressionL2SmoothedL1TV(l1=0., l2=0., tv=0., A = A)\n",
    "                    GridSearch = GridSearchKFoldRegression(tvenet_estimator, param_grid, maximise=False, K = 10)\n",
    "                    GridSearch.fit(X, y[:,i, j])\n",
    "                    score_st += [GridSearch._best_results]\n",
    "                    best_params_st += [GridSearch._best_params]\n",
    "\n",
    "\n",
    "\n",
    "                    X = get_nodes_attribute(MinM_think, MinM_log_jac, MinM_mesh_area, mean_labels, i, j)\n",
    "\n",
    "                    tvenet_estimator = estimators.LinearRegressionL2SmoothedL1TV(l1=0.1, l2=0.1, tv=0.1, A = A)\n",
    "                    GridSearch = GridSearchKFoldRegression(tvenet_estimator, param_grid,maximise=False, K = 10)\n",
    "                    GridSearch.fit(X, y[:,i, j])\n",
    "                    score_mm += [GridSearch._best_results]\n",
    "                    best_params_mm += [GridSearch._best_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_st = np.array(score_st)\n",
    "best_params_st = np.array(best_params_st)\n",
    "score_mm = np.array(score_mm)\n",
    "best_params_mm = np.array(best_params_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_dir = 'exper_tv_nodes_to_edge'\n",
    "edge = '/edge[' + str(i) + ',' + str(j) + ']'\n",
    "if !os.path.exists(name_dir):\n",
    "    os.mkdir(name_dir)\n",
    "    \n",
    "    if !os.path.exists(name_dir + edge):\n",
    "        os.mkdir(name_dir + edge)\n",
    "\n",
    "with open(name_dir + edge + '/score_st.pkl', 'wb') as f:\n",
    "    pickle.dump(score_st,f)\n",
    "with open(name_dir + edge + '/score_mm.pkl', 'wb') as f:\n",
    "    pickle.dump(score_mm,f)\n",
    "with open(name_dir + edge + '/best_params_st.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params_st,f)\n",
    "with open(name_dir + edge + '/best_params_mm.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params_mm,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
