{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 789, 68)\n",
      "Fit ElasticNet for weighted degree\n",
      "clustering\n",
      "(789, 68)\n",
      "Fit ElasticNet for  clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nmnt/media/home/ayagoz/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/nmnt/media/home/ayagoz/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/nmnt/media/home/ayagoz/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/nmnt/media/home/ayagoz/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/nmnt/media/home/ayagoz/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/nmnt/media/home/ayagoz/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/nmnt/media/home/ayagoz/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/nmnt/media/home/ayagoz/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/nmnt/media/home/ayagoz/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/nmnt/media/home/ayagoz/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c9a4013ede78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m                             n_jobs=-1, cv = 10)\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rank_test_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 638\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "from utils import get_nodes_attribute, get_all_attr, rich_cl, to_degree, local_measure\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "\n",
    "\n",
    "path_data = \"/nmnt/x01-hdd/HCP/data/\"\n",
    "\n",
    "with open(path_data + \"normed_connectomes\", 'rb') as f:\n",
    "    Y = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_roi_thinkness\", 'rb') as f:\n",
    "    roi_think = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_roi_volume\", 'rb') as f:\n",
    "    roi_volume = pickle.load(f)\n",
    "    \n",
    "targets_name = ['clustering', 'rich_club', 'betweenness', 'closeness',  'degree_centrality', 'eigenvector']\n",
    "\n",
    "targets_data = []\n",
    "for name in targets_name:\n",
    "    with open(path_data + name, 'rb') as f:\n",
    "        targets_data  += [pickle.load(f)]\n",
    "\n",
    "print(np.array(targets_data).shape)\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "elastic_param = {'alpha': [ 1e-5, 1e-3, 0.1, 1.0, 5, 10, 20, 50, 70, 100,], \n",
    "                 'l1_ratio': [1e-10, 1e-7, 1e-3, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                 'max_iter':[1000, 10000]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_res = '/nmnt/x03-hdd/'\n",
    "\n",
    "\n",
    "if not os.path.exists(path_res + 'roi_node'):\n",
    "    os.mkdir(path_res + 'roi_node')\n",
    "path_res += 'roi_node/'\n",
    "\n",
    "wdeg = Y.sum(axis = -1)                 \n",
    "X = np.concatenate([roi_think, roi_volume], axis= -1)\n",
    "print('Fit ElasticNet for weighted degree')\n",
    "elastic = ElasticNet()\n",
    "StanS = StandardScaler()\n",
    "MinM = MinMaxScaler()\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "rg =GridSearchCV(elastic, elastic_param, scoring = 'r2', \n",
    "                        n_jobs=-1, cv = 10)\n",
    "\n",
    "rg.fit(X, wdeg)\n",
    "orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(StanS.fit_transform(X), wdeg)\n",
    "st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(MinM.fit_transform(X), wdeg)\n",
    "mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "name_dir = 'exper_elastic_roi_node_weighted_degree'\n",
    "if not os.path.exists(path_res + name_dir):\n",
    "    os.mkdir(path_res + name_dir)\n",
    "\n",
    "\n",
    "orig.to_csv(path_res + name_dir +'/results_orig')\n",
    "st.to_csv(path_res + name_dir + '/results_st')\n",
    "mm.to_csv(path_res + name_dir + '/results_mm')\n",
    "#print(path_res)\n",
    "for j, target in enumerate(targets_data):\n",
    "    print(targets_name[j])\n",
    "    print(target.shape)\n",
    "\n",
    "    print('Fit ElasticNet for ', targets_name[j])\n",
    "    elastic = ElasticNet()\n",
    "    StanS = StandardScaler()\n",
    "    MinM = MinMaxScaler()\n",
    "    cv = ShuffleSplit(test_size=0.2)\n",
    "    rg =GridSearchCV(elastic, elastic_param, scoring = 'r2', \n",
    "                            n_jobs=-1, cv = 10)\n",
    "    \n",
    "    rg.fit(X, target)\n",
    "    orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "    orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "    rg.fit(StanS.fit_transform(X), target)\n",
    "    st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "    st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "    rg.fit(MinM.fit_transform(X), target)\n",
    "    mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "    mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "    name_dir = 'exper_elastic_roi_node_' + targets_name[j]\n",
    "    if not os.path.exists(path_res + name_dir):\n",
    "        os.mkdir(path_res + name_dir)\n",
    "\n",
    "\n",
    "    orig.to_csv(path_res + name_dir +'/results_orig')\n",
    "    st.to_csv(path_res + name_dir + '/results_st')\n",
    "    mm.to_csv(path_res + name_dir + '/results_mm')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(path_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nmnt/x03-hdd/roi_node/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 789, 68)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "from utils import get_nodes_attribute, get_all_attr, rich_cl, to_degree, local_measure\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "\n",
    "\n",
    "path_data = \"/nmnt/x01-hdd/HCP/data/\"\n",
    "\n",
    "with open(path_data + \"mean_mesh_labels\", 'rb') as f:\n",
    "    mean_labels = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(path_data + \"subjects_log_jac\", 'rb') as f:\n",
    "    log_jac = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_thinkness\", 'rb') as f:\n",
    "    thinkness = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_mesh_area\", 'rb') as f:\n",
    "    mesh_area = pickle.load(f)\n",
    "\n",
    "\n",
    "targets_name = ['clustering', 'rich_club', 'betweenness', 'closeness',  'degree_centrality', 'eigenvector']\n",
    "\n",
    "targets_data = []\n",
    "for name in targets_name:\n",
    "    with open(path_data + name, 'rb') as f:\n",
    "        targets_data  += [pickle.load(f)]\n",
    "\n",
    "print(np.array(targets_data).shape)\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "elastic_param = {'alpha': [ 1e-5, 1e-3, 0.1, 1.0, 5, 10, 20, 50, 70, 100,], \n",
    "                 'l1_ratio': [1e-10, 1e-7, 1e-3, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                 'max_iter':[10000]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_res = '/nmnt/x03-hdd/HCP/'\n",
    "                   \n",
    "\n",
    "\n",
    "thinkness = thinkness.reshape(789,-1)\n",
    "log_jac = log_jac.reshape(789,-1)\n",
    "mesh_area = mesh_area.reshape(789,-1)\n",
    "\n",
    "X = np.concatenate([thinkness, log_jac, mesh_area], axis = -1)\n",
    "\n",
    "\n",
    "# for j, target in enumerate(targets_data):\n",
    "#     print(targets_name[j])\n",
    "#     print(target.shape)cddu =\n",
    "\n",
    "#     elastic = ElasticNet()\n",
    "#     StanS = StandardScaler()\n",
    "#     MinM = MinMaxScaler()\n",
    "#     cv = ShuffleSplit(test_size=0.2)\n",
    "#     rg = GridSearchCV(elastic, elastic_param, scoring = 'r2', \n",
    "#                             n_jobs=-1, cv = 10)\n",
    "\n",
    "#     rg.fit(X, target)\n",
    "#     orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "#     orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "#     rg.fit(StanS.fit_transform(X), target)\n",
    "#     st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "#     st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "#     rg.fit(MinM.fit_transform(X), target)\n",
    "#     mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "#     mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "#     name_dir = 'exper_elastic_all_meshes_to_node'\n",
    "#     edge = '/edge[' + targets_name[j] + ']'\n",
    "#     if not os.path.exists(path_res + name_dir):\n",
    "#         os.mkdir(path_res + name_dir)\n",
    "\n",
    "#     if not os.path.exists(path_res + name_dir + edge):\n",
    "#         os.mkdir(path_res + name_dir + edge)\n",
    "#     orig.to_csv(path_res + name_dir + edge +'/results_orig')\n",
    "#     st.to_csv(path_res + name_dir + edge + '/results_st')\n",
    "#     mm.to_csv(path_res + name_dir + edge + '/results_mm')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 789, 68)\n",
      "(68,)\n",
      "clustering\n",
      "(789, 68)\n",
      "1\n",
      "0\n",
      "build\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "from utils import get_nodes_attribute, get_all_attr, rich_cl, to_degree, local_measure\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "\n",
    "\n",
    "path_data = \"/nmnt/x01-hdd/HCP/data/\"\n",
    "\n",
    "with open(path_data + \"mean_mesh_labels\", 'rb') as f:\n",
    "    mean_labels = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(path_data + \"subjects_log_jac\", 'rb') as f:\n",
    "    log_jac = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_thinkness\", 'rb') as f:\n",
    "    thinkness = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_mesh_area\", 'rb') as f:\n",
    "    mesh_area = pickle.load(f)\n",
    "\n",
    "\n",
    "targets_name = ['clustering', 'rich_club', 'betweenness', 'closeness',  'degree_centrality', 'eigenvector']\n",
    "\n",
    "targets_data = []\n",
    "for name in targets_name:\n",
    "    with open(path_data + name, 'rb') as f:\n",
    "        targets_data  += [pickle.load(f)]\n",
    "\n",
    "print(np.array(targets_data).shape)\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "elastic_param = {'alpha': [ 1e-5, 1e-3, 0.1, 1.0, 5, 10, 20, 50, 70, 100,], \n",
    "                 'l1_ratio': [1e-10, 1e-7, 1e-3, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                 'max_iter':[10000]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_res = '/nmnt/x03-hdd/HCP/'\n",
    "                   \n",
    "\n",
    "\n",
    "thinkness = thinkness.reshape(789,-1)\n",
    "log_jac = log_jac.reshape(789,-1)\n",
    "mesh_area = mesh_area.reshape(789,-1)\n",
    "\n",
    "\n",
    "\n",
    "idx_nodes = list(range(1,4)) + list(range(5,39)) + list(range(40,71))\n",
    "idx_nodes = np.array(idx_nodes)\n",
    "print(idx_nodes.shape)\n",
    "\n",
    "for j, target in enumerate(targets_data):\n",
    "    print(targets_name[j])\n",
    "    print(target.shape)\n",
    "    \n",
    "    for i in range(68):\n",
    "        node1 = idx_nodes[i]\n",
    "        print(node1)\n",
    "        print(i)\n",
    "            \n",
    "        X = get_nodes_attribute(thinkness, log_jac, mesh_area, mean_labels, node1)\n",
    "        elastic = ElasticNet()\n",
    "        StanS = StandardScaler()\n",
    "        MinM = MinMaxScaler()\n",
    "        cv = ShuffleSplit(test_size=0.2)\n",
    "        rg = GridSearchCV(elastic, elastic_param, scoring = 'r2', \n",
    "                                n_jobs=-1, cv = 10)\n",
    "\n",
    "        rg.fit(X, target[:,i])\n",
    "        orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "        orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "        rg.fit(StanS.fit_transform(X), target[:,i])\n",
    "        st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "        st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "        rg.fit(MinM.fit_transform(X), target[:,i])\n",
    "        mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "        mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "        name_dir = 'exper_elastic_all_meshes_to_node'\n",
    "        edge = '/edge[' + str(i) + targets_name[j] + ']'\n",
    "        if not os.path.exists(path_res + name_dir):\n",
    "            os.mkdir(path_res + name_dir)\n",
    "        \n",
    "        if not os.path.exists(path_res + name_dir + edge):\n",
    "            os.mkdir(path_res + name_dir + edge)\n",
    "        orig.to_csv(path_res + name_dir + edge +'/results_orig')\n",
    "        st.to_csv(path_res + name_dir + edge + '/results_st')\n",
    "        mm.to_csv(path_res + name_dir + edge + '/results_mm')\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 789, 68)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "from utils import get_nodes_attribute, get_all_attr, rich_cl, to_degree, local_measure\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "\n",
    "\n",
    "path_data = \"/nmnt/x01-hdd/HCP/data/\"\n",
    "\n",
    "with open(path_data + \"mean_mesh_labels\", 'rb') as f:\n",
    "    mean_labels = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(path_data + \"subjects_log_jac\", 'rb') as f:\n",
    "    log_jac = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_thinkness\", 'rb') as f:\n",
    "    thinkness = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_mesh_area\", 'rb') as f:\n",
    "    mesh_area = pickle.load(f)\n",
    "\n",
    "\n",
    "targets_name = ['clustering', 'rich_club', 'betweenness', 'closeness',  'degree_centrality', 'eigenvector']\n",
    "\n",
    "targets_data = []\n",
    "for name in targets_name:\n",
    "    with open(path_data + name, 'rb') as f:\n",
    "        targets_data  += [pickle.load(f)]\n",
    "\n",
    "print(np.array(targets_data).shape)\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "elastic_param = {'alpha': [ 1e-5, 1e-3, 0.1, 1.0, 5, 10, 20, 50, 70, 100,], \n",
    "                 'l1_ratio': [1e-10, 1e-7, 1e-3, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                 'max_iter':[10000]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_res = '/nmnt/x03-hdd/HCP/'\n",
    "                   \n",
    "\n",
    "\n",
    "thinkness = thinkness.reshape(789,-1)\n",
    "log_jac = log_jac.reshape(789,-1)\n",
    "mesh_area = mesh_area.reshape(789,-1)\n",
    "\n",
    "idx_nodes = list(range(1,4)) + list(range(5,39)) + list(range(40,71))\n",
    "idx_nodes = np.array(idx_nodes)\n",
    "print(idx_nodes.shape)\n",
    "for j, target in enumerate(targets_data):\n",
    "    print(targets_name[j])\n",
    "    for i in range(68):\n",
    "            node1 = idx_nodes[i]\n",
    "            print(node1)\n",
    "            print(i)\n",
    "\n",
    "            X = get_nodes_attribute(thinkness, log_jac, mesh_area, mean_labels, node1)\n",
    "            \n",
    "            elastic = ElasticNet()\n",
    "            StanS = StandardScaler()\n",
    "            MinM = MinMaxScaler()\n",
    "            cv = ShuffleSplit(test_size=0.2)\n",
    "            rg = GridSearchCV(elastic, elastic_param, scoring = 'r2', \n",
    "                                    n_jobs=-1, cv = 10)\n",
    "\n",
    "            rg.fit(X, target[:, i])\n",
    "            orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "            orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "            rg.fit(StanS.fit_transform(X), target[:, i])\n",
    "            st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "            st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "            rg.fit(MinM.fit_transform(X), target[:, i])\n",
    "            mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "            mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "            name_dir = 'exper_elastic_nodes_to_node'\n",
    "            edge = '/edge[' + str(i) + ',' + targets_name[j] + ']'\n",
    "            if not os.path.exists(path_res + name_dir):\n",
    "                os.mkdir(path_res + name_dir)\n",
    "\n",
    "            if not os.path.exists(path_res + name_dir + edge):\n",
    "                os.mkdir(path_res + name_dir + edge)\n",
    "            orig.to_csv(path_res + name_dir + edge +'/results_orig')\n",
    "            st.to_csv(path_res + name_dir + edge + '/results_st')\n",
    "            mm.to_csv(path_res + name_dir + edge + '/results_mm')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('Fit ElasticNet for clustering')\n",
    "elastic = ElasticNet()\n",
    "StanS = StandardScaler()\n",
    "MinM = MinMaxScaler()\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "rg =GridSearchCV(elastic, elastic_param, scoring = 'r2', \n",
    "                        n_jobs=-1, cv = 10)\n",
    "\n",
    "rg.fit(X, clustering)\n",
    "orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(StanS.fit_transform(X), clustering)\n",
    "st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(MinM.fit_transform(X), clustering)\n",
    "mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "name_dir = 'exper_elastic_roi_node_clustering'\n",
    "if not os.path.exists(path_res + name_dir):\n",
    "    os.mkdir(path_res + name_dir)\n",
    "\n",
    "\n",
    "orig.to_csv(path_res + name_dir +'/results_orig')\n",
    "st.to_csv(path_res + name_dir + '/results_st')\n",
    "mm.to_csv(path_res + name_dir + '/results_mm')\n",
    "\n",
    "\n",
    "print('Fit ElasticNet for rich_club')\n",
    "elastic = ElasticNet()\n",
    "StanS = StandardScaler()\n",
    "MinM = MinMaxScaler()\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "rg =GridSearchCV(elastic, elastic_param, scoring = 'r2', \n",
    "                        n_jobs=-1, cv = 10)\n",
    "\n",
    "rg.fit(X, rich_club)\n",
    "orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(StanS.fit_transform(X), rich_club)\n",
    "st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(MinM.fit_transform(X), rich_club)\n",
    "mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "name_dir = 'exper_elastic_roi_node_rich_club'\n",
    "if not os.path.exists(path_res + name_dir):\n",
    "    os.mkdir(path_res + name_dir)\n",
    "\n",
    "\n",
    "orig.to_csv(path_res + name_dir +'/results_orig')\n",
    "st.to_csv(path_res + name_dir + '/results_st')\n",
    "mm.to_csv(path_res + name_dir + '/results_mm')\n",
    "\n",
    "\n",
    "print('Fit ElasticNet for betweenness')\n",
    "elastic = ElasticNet()\n",
    "StanS = StandardScaler()\n",
    "MinM = MinMaxScaler()\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "rg =GridSearchCV(elastic, elastic_param, scoring = 'r2', \n",
    "                        n_jobs=-1, cv = 10)\n",
    "\n",
    "rg.fit(X, between)\n",
    "orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(StanS.fit_transform(X), between)\n",
    "st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(MinM.fit_transform(X), between)\n",
    "mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "name_dir = 'exper_elastic_roi_node_between'\n",
    "if not os.path.exists(path_res + name_dir):\n",
    "    os.mkdir(path_res + name_dir)\n",
    "\n",
    "\n",
    "orig.to_csv(path_res + name_dir +'/results_orig')\n",
    "st.to_csv(path_res + name_dir + '/results_st')\n",
    "mm.to_csv(path_res + name_dir + '/results_mm')\n",
    "\n",
    "print('Fit ElasticNet for closeness')\n",
    "elastic = ElasticNet()\n",
    "StanS = StandardScaler()\n",
    "MinM = MinMaxScaler()\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "rg =GridSearchCV(elastic, elastic_param, scoring = 'r2', \n",
    "                        n_jobs=-1, cv = 10)\n",
    "\n",
    "rg.fit(X, closeness)\n",
    "orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(StanS.fit_transform(X), closeness)\n",
    "st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(MinM.fit_transform(X), closeness)\n",
    "mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "name_dir = 'exper_elastic_roi_node_closeness'\n",
    "if not os.path.exists(path_res + name_dir):\n",
    "    os.mkdir(path_res + name_dir)\n",
    "\n",
    "\n",
    "orig.to_csv(path_res + name_dir +'/results_orig')\n",
    "st.to_csv(path_res + name_dir + '/results_st')\n",
    "mm.to_csv(path_res + name_dir + '/results_mm')\n",
    "\n",
    "print('Fit ElasticNet for degree centrality')\n",
    "elastic = ElasticNet()\n",
    "StanS = StandardScaler()\n",
    "MinM = MinMaxScaler()\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "rg =GridSearchCV(elastic, elastic_param, scoring = 'r2', \n",
    "                        n_jobs=-1, cv = 10)\n",
    "\n",
    "rg.fit(X, degree_cent)\n",
    "orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(StanS.fit_transform(X), degree_cent)\n",
    "st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(MinM.fit_transform(X), degree_cent)\n",
    "mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "name_dir = 'exper_elastic_roi_node_deg_cent'\n",
    "if not os.path.exists(path_res + name_dir):\n",
    "    os.mkdir(path_res + name_dir)\n",
    "\n",
    "\n",
    "orig.to_csv(path_res + name_dir +'/results_orig')\n",
    "st.to_csv(path_res + name_dir + '/results_st')\n",
    "mm.to_csv(path_res + name_dir + '/results_mm')\n",
    "\n",
    "print('Fit ElasticNet for eigenvector cent')\n",
    "elastic = ElasticNet()\n",
    "StanS = StandardScaler()\n",
    "MinM = MinMaxScaler()\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "rg =GridSearchCV(elastic, elastic_param, scoring = 'r2', \n",
    "                        n_jobs=-1, cv = 10)\n",
    "\n",
    "rg.fit(X, eigen)\n",
    "orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(StanS.fit_transform(X), eigen)\n",
    "st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "rg.fit(MinM.fit_transform(X), eigen)\n",
    "mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "name_dir = 'exper_elastic_roi_node_eigenvector'\n",
    "if not os.path.exists(path_res + name_dir):\n",
    "    os.mkdir(path_res + name_dir)\n",
    "\n",
    "\n",
    "orig.to_csv(path_res + name_dir +'/results_orig')\n",
    "st.to_csv(path_res + name_dir + '/results_st')\n",
    "mm.to_csv(path_res + name_dir + '/results_mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path_data + 'clustering', 'rb') as f:\n",
    "    clustering = pickle.load(f)\n",
    "\n",
    "with open(path_data + 'rich_club', 'rb') as f:\n",
    "    rich_club = pickle.load(f)\n",
    "\n",
    "with open(path_data + 'betweenness', 'rb') as f:\n",
    "    between = pickle.load(f)\n",
    "\n",
    "with open(path_data + 'closeness', 'rb') as f:\n",
    "    closeness = pickle.load(f)\n",
    "\n",
    "with open(path_data + 'degree_centrality', 'rb') as f:\n",
    "    degree_cent = pickle.load(f)\n",
    "\n",
    "with open(path_data + 'eigenvector', 'rb') as f:\n",
    "    eigen = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.73 s ± 35.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "local_measure(Y[:10], 'clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 204823.08075925,  176176.49580132,  229029.4447882 ,\n",
       "         134006.588865  ,  159957.07212225,  195296.42589546,\n",
       "         242242.68199838,  189422.84904748,  189422.84904748,\n",
       "         181900.64181638,  196056.33410322,  179951.70658933,\n",
       "         171967.50127321,  230075.24134056,  227993.11228163,\n",
       "         229029.44496621,  214410.54428041,  195296.42583074,\n",
       "         188009.24545557,  190137.6522519 ,  205659.09326288,\n",
       "         213502.02463661,  146047.76159944,  120254.12216487,\n",
       "         146899.3524478 ,  147328.88235046,   50135.80077356,\n",
       "         120254.12292554,  190137.6522519 ,  220028.28698769,\n",
       "         169651.4405985 ,  139574.73048987,  185927.9626488 ,\n",
       "         166292.00603451,  197594.03084283,  132247.97338443,\n",
       "         192314.80119425,  180596.69456401,  129528.21892252,\n",
       "         147760.9310063 ,  168516.64840091,  171382.57784865,\n",
       "         127560.70258172,  140352.30578897,  215326.82842333,\n",
       "         142334.68326296,  248209.25052553,  181246.32312855,\n",
       "         179951.70658933,  161495.12097822,  180596.69473004,\n",
       "         196056.334038  ,  196056.334038  ,  138045.14466421,\n",
       "         170224.5868661 ,  150407.39661396,  189422.84892572,\n",
       "         132247.97305799,  177417.17550908,  151310.74430345,\n",
       "         148195.52294579,  156967.22018704,  214410.5441244 ,\n",
       "         219071.64283348,  226966.11619295,  160466.48994165,\n",
       "         180596.69445333,  160979.16243376],\n",
       "       [ 189867.98899513,  178807.717513  ,  186976.59783804,\n",
       "         180560.73422998,  159456.23312468,  164439.2401095 ,\n",
       "         156742.08440537,   97188.36185839,  132022.90221374,\n",
       "         165920.67460165,   85861.04707233,  192850.20845148,\n",
       "         141127.93020772,  161554.34109062,  184171.94854443,\n",
       "         183255.67042937,  178807.7174045 ,  132976.13651661,\n",
       "         156077.92319963,  192850.20845148,  156077.92278628,\n",
       "         202386.7568841 ,  169743.73188483,   70835.36219224,\n",
       "         171322.74323544,  107702.8937258 ,   94447.15326015,\n",
       "         115107.46839783,  172931.40727781,  139524.20420116,\n",
       "         160149.52091732,  159456.23286582,  157411.92228524,\n",
       "         126145.17069168,  154766.3439373 ,  143324.473993  ,\n",
       "         193865.20954258,  154766.34369344,  119592.17503766,\n",
       "         198034.35394169,  138475.14990754,  181450.1958572 ,\n",
       "         102317.7495182 ,  155419.36623654,  167429.04435961,\n",
       "         178807.71762151,  217954.96866422,  175401.85614291,\n",
       "         142217.72082401,  188894.30676247,  162984.02560492,\n",
       "         184171.94888976,  150960.61410856,  181450.1961924 ,\n",
       "         176241.0993628 ,   66728.96490916,  177943.91211961,\n",
       "         124021.51478675,  198034.35367551,  134432.07942454,\n",
       "         125287.04028319,  162984.02596551,  177088.41254725,\n",
       "         189867.98862811,  161554.34179921,  145017.28287369,\n",
       "         174570.56752374,   66011.44890348],\n",
       "       [ 165362.55098385,  121706.83749652,  158472.44474658,\n",
       "         178281.49991444,  134235.48274858,  161844.19890772,\n",
       "         159580.64349375,  151628.12016905,   54268.80470062,\n",
       "         185528.71625474,  178980.64332505,  197576.03479415,\n",
       "         148182.02665449,  147702.47268521,  154189.40571843,\n",
       "         183293.42992998,  142180.884863  ,  174866.14581214,\n",
       "         157924.09684557,  187049.44309254,  150131.78937534,\n",
       "          58890.4050845 ,  122359.42120559,  120740.91077939,\n",
       "         169037.27425999,  116428.73537908,   58890.40506685,\n",
       "         139146.53728962,  112413.95095786,  101875.14402778,\n",
       "         184032.51611434,  184777.58737973,  143974.9653662 ,\n",
       "          53008.20442489,  184032.51640168,  178980.64332505,\n",
       "         160704.45115365,  157379.53124494,  122032.25667271,\n",
       "         114673.52765027,  182560.25643329,  124021.91290729,\n",
       "         153670.24930723,  184777.58714799,  156838.70857019,\n",
       "         153154.57740715,  193390.10171019,  151126.03979367,\n",
       "         143072.30103798,  164172.89197217,  125041.27138957,\n",
       "         163000.22854533,  116428.73549409,  164765.5739402 ,\n",
       "         180395.51013199,  160140.5765358 ,  165362.55089105,\n",
       "         105893.42085124,  181111.36544554,   95681.47695158,\n",
       "         145350.52232938,  152642.3550146 ,  168413.52067027,\n",
       "         170298.74626459,  173536.36543415,  171579.18801988,\n",
       "         137057.25002154,  180395.50985589],\n",
       "       [ 196447.79968836,  146535.98135076,  167236.23244982,\n",
       "         182131.76587257,  162406.30380455,  149456.96479415,\n",
       "         142362.48711481,  147982.05902258,  167860.24624797,\n",
       "         205418.01882782,  107366.46050613,  179229.26888098,\n",
       "         160666.23676663,  140582.95721871,  166616.83719297,\n",
       "         200832.79486326,  173693.22834819,  148962.07372117,\n",
       "         177112.38653821,  137995.54052727,  191432.11199431,\n",
       "         131925.35543491,  179946.18476262,  121257.5381928 ,\n",
       "         189816.65025063,  130018.92026687,  161242.10001229,\n",
       "          83618.1167232 ,  164184.47421454,  155126.02202654,\n",
       "         129271.68473856,  161822.1093481 ,  156203.28526035,\n",
       "         156203.28426671,  177112.38611239,  201733.39091822,\n",
       "         154592.94249773,  171051.5062103 ,  120931.57621689,\n",
       "         171051.50660747,  166002.01640521,  176417.82815006,\n",
       "          67044.03554627,  183618.55581844,  134690.25856513,\n",
       "         179946.18487251,  193907.52689517,  179229.26757281,\n",
       "         153537.70007292,  186666.16698236,  170403.58333734,\n",
       "         157847.53148959,  114469.5846873 ,  191432.11186995,\n",
       "         199055.51347358,  172362.2454359 ,  104135.52396691,\n",
       "         114179.05167677,  177812.43497009,   65578.05769848,\n",
       "         156203.28426671,  138847.36434056,  161242.10027699,\n",
       "         171704.37496319,  135911.0170952 ,  174366.4574083 ,\n",
       "         202642.09892333,  168488.93650762],\n",
       "       [ 199578.04457309,  178788.66512053,  177311.07274501,\n",
       "         183372.98968035,  174427.96603707,   59679.10748501,\n",
       "         143509.29658221,  160109.25253306,   96425.34690324,\n",
       "         151089.0129335 ,  166315.03717241,  185754.45712684,\n",
       "         110590.92708171,  162535.15020371,   89580.95968127,\n",
       "         195042.18020142,  166962.17748672,  168934.17184693,\n",
       "         151622.89625316,  175857.70330191,  189864.06905413,\n",
       "         170953.30526994,  179536.73479187,   74109.2919829 ,\n",
       "         163775.8762191 ,  139315.84308664,  101680.75638546,\n",
       "          73981.51736856,  119192.44361859,  153796.70113029,\n",
       "         175857.70330191,  113217.09674131,  179536.73479187,\n",
       "         144963.78255037,  126576.04636231,  149509.68523785,\n",
       "         167614.3733471 ,  142555.74626847,   68435.85175378,\n",
       "         171637.11843865,  161921.80983799,  140686.16268351,\n",
       "          60778.01452447,  185754.45706829,  178046.80333442,\n",
       "         181818.98141213,  161313.0811436 ,  186562.08525704,\n",
       "         184953.79136663,  172326.42428374,  160708.91256595,\n",
       "         166962.17758132,  146949.58789427,  157754.70453782,\n",
       "         175857.70340687,  137529.74228166,  160109.25231557,\n",
       "         138417.03119787,  163153.15448506,  165035.69096907,\n",
       "          67045.75005582,  114120.42483746,  140686.16278426,\n",
       "         167614.37353779,  171637.11858861,  100963.01008694,\n",
       "         137971.96042365,  151622.89621415],\n",
       "       [ 177948.48654196,  198772.24507543,  163184.20317726,\n",
       "         127976.65206361,  147122.76423647,  158343.99258201,\n",
       "         187784.83438895,  117144.77365183,  121723.72115898,\n",
       "         144841.7917782 ,  166085.25469425,  194631.15675124,\n",
       "         177948.4864345 ,  187784.83450862,  177105.12941944,\n",
       "         179659.52925407,  181403.7966465 ,  159697.36005098,\n",
       "         169091.32151747,  177948.4864345 ,  199835.19866782,\n",
       "         176269.7266977 ,  171418.26681436,   98339.95466117,\n",
       "         184995.95093518,  151292.23507393,  161771.35166822,\n",
       "         148290.40567551,  176269.72733037,  185916.32927322,\n",
       "         127539.87095821,  170635.53470146,  131119.93712691,\n",
       "         205325.1762546 ,  188733.24312939,  145973.36814193,\n",
       "         178799.91438692,  196679.90617171,  199835.19812574,\n",
       "         143176.94455623,  163899.92173683,  133461.36476543,\n",
       "         138918.89278643,  193622.7047762 ,  196679.90604043,\n",
       "         186845.91104396,  191636.83112645,  184995.95174818,\n",
       "         208766.38063391,  174622.34648341,  188733.24288763,\n",
       "         199835.1985323 ,  198772.24507543,  194631.15662269,\n",
       "         150077.03692997,  122121.50988751,  171418.26641548,\n",
       "         153782.64200267,  157675.87438012,  109587.04420299,\n",
       "         135395.58732854,  154418.10770926,  170635.53529432,\n",
       "         175442.1692929 ,  177948.48600465,  211125.32219472,\n",
       "         133461.36446319,  183182.26502106],\n",
       "       [ 164719.15328865,  167030.99986126,  148298.55351615,\n",
       "         172477.66365792,  137583.33858689,  136400.67452762,\n",
       "         200016.11309441,  147380.2967865 ,  142100.99975814,\n",
       "         161368.9333453 ,  170013.69602062,  171236.81684167,\n",
       "         167619.1386203 ,  163587.06205247,  137982.13139477,\n",
       "         211572.60215887,  183091.67399462,  173736.62472359,\n",
       "          74149.27690735,  183091.67308452,  151123.28607827,\n",
       "         109686.25769582,  183798.59132149,  145133.64307106,\n",
       "         213470.11246859,   91370.12606538,   72677.61260253,\n",
       "         103038.60583048,  163026.83229151,  129358.24736485,\n",
       "         167619.13804821,  176965.92942278,  149697.59430254,\n",
       "         152576.39374728,  156078.14797989,  104394.37722112,\n",
       "         180317.55757089,  154057.71990154,  132971.607229  ,\n",
       "         153066.99396203,  114985.10930719,  156078.14748386,\n",
       "         140011.28168457,  143385.04536593,  149697.59589958,\n",
       "         185952.48085739,  146925.41770289,  157108.36628902,\n",
       "         156591.56269725,  181694.0267113 ,  145133.64450071,\n",
       "         191180.06058093,  171236.81644364,  193511.52412651,\n",
       "         157108.36645655,  125936.07088149,  147837.99735926,\n",
       "         142100.99975814,  163587.06250655,   87829.95352859,\n",
       "          71156.70589167,  142526.4519946 ,  142954.46019412,\n",
       "         124291.99731192,  187416.67328013,  119009.58925376,\n",
       "         183798.59063362,  185228.93068888],\n",
       "       [ 152190.76578386,  182334.83050434,  159929.2792983 ,\n",
       "         180589.99959042,  148595.7083244 ,  170784.20775746,\n",
       "         136751.12287825,   96530.20438465,   75335.94793293,\n",
       "         167005.79608141,  165540.83295789,  154054.32618122,\n",
       "         170784.20775746,  133841.52451914,  148595.7083244 ,\n",
       "         194553.14388865,  127081.85156363,  113684.66841686,\n",
       "         170014.90952431,  159254.47221265,  120201.6239312 ,\n",
       "         120972.14716153,  154054.32618122,   59066.21288802,\n",
       "         161988.45456823,   87571.48472018,   99586.56969498,\n",
       "          82952.32948219,  151579.55788915,  150371.752647  ,\n",
       "         161988.45456823,  160609.82942297,  158585.33577478,\n",
       "         103406.3285326 ,  161988.45456823,  129702.09592577,\n",
       "         163390.95237277,  150371.752647  ,  131509.7906425 ,\n",
       "         159254.47221265,  181458.2207423 ,  162686.68066551,\n",
       "         101460.51052257,  167748.04406399,  165540.83295789,\n",
       "         162686.68066551,  148595.7083244 ,  154685.69637048,\n",
       "         161296.19621538,  149183.04313991,  139790.03698526,\n",
       "         168496.9192607 ,  155322.26302221,  134317.82887686,\n",
       "         160609.82942297,  119064.06913059,  154054.32650338,\n",
       "          86966.15187649,  101460.51052257,  127081.85156363,\n",
       "          95071.30960806,   61172.30131993,  175550.27867162,\n",
       "         166270.08772862,  146861.12807159,  169252.51121576,\n",
       "         136751.12287825,  157263.79130999],\n",
       "       [ 201657.88341352,  152255.75107494,  181395.6076243 ,\n",
       "         185841.57817621,  174708.21234999,  189558.41035423,\n",
       "         167750.80524981,  173112.70294371,  134917.01842654,\n",
       "         195421.04227752,  163412.42261766,  196433.58602233,\n",
       "         138870.63169964,  179676.21808394,  157965.34209735,\n",
       "         184037.29169685,  165553.19681452,  177157.3924827 ,\n",
       "         193426.94961276,  200590.91007068,  198490.48155361,\n",
       "         137860.661713  ,  185841.57923107,  105603.57340168,\n",
       "         192445.0869186 ,  119595.21274028,   88994.56043995,\n",
       "         140935.62125546,  172325.82712109,  170773.34218938,\n",
       "         168496.36428961,  145255.48685181,  138870.63104517,\n",
       "         165553.19672151,  190510.96469176,  197456.67682779,\n",
       "         215407.28446825,  194418.88192394,  148673.26355363,\n",
       "         147516.27220648,  159964.90366109,  169248.58030013,\n",
       "         131182.29118787,  190510.96518444,  182267.70200663,\n",
       "         144701.07737583,  186757.05393194,  153488.59172812,\n",
       "         170007.54313389,  197456.67735705,  189558.40962258,\n",
       "         208305.94509521,  188615.3338023 ,  179676.2181935 ,\n",
       "         177989.11765458,  170007.54283963,  199535.16857098,\n",
       "          73472.25137804,  220416.75622255,  174708.21276433,\n",
       "         145814.16165942,   79147.56171828,  167011.81557925,\n",
       "         200590.91034378,  174708.21286791,  151042.55814524,\n",
       "         166279.30695483,  141461.50051019],\n",
       "       [ 145545.03576942,   81744.471775  ,  101356.20329404,\n",
       "         125959.82312953,  105616.75185389,  120552.45394901,\n",
       "         153500.87440502,  115311.0434718 ,  100081.28268517,\n",
       "         102885.28682362,  132240.36499176,  140822.33580518,\n",
       "          86015.806116  ,  109242.04271828,  161279.63551416,\n",
       "         154996.01298109,  156520.56420621,  142503.79752165,\n",
       "         123038.07300325,  104690.29035052,   64337.96991673,\n",
       "         124319.71823982,   99455.77445759,   72995.06674315,\n",
       "         164050.76333076,   81744.471775  ,   99455.77445759,\n",
       "          64424.7939747 ,  142079.67893033,  144225.89776157,\n",
       "         116436.03077795,  149183.66201367,  146888.52886404,\n",
       "         116152.7296156 ,  134475.416145  ,  134855.28753011,\n",
       "         127643.77630851,  140408.15279288,  100081.28513256,\n",
       "         135237.3141871 ,  123038.07187302,  135621.51095272,\n",
       "          45639.36144658,  124644.31270364,  154996.01306262,\n",
       "          94908.09786441,  129373.3669886 ,  131875.06205881,\n",
       "          86015.80635453,  117006.79460735,  115033.18663084,\n",
       "         140822.33577153,  154996.01294033,  138775.50100179,\n",
       "         104690.29250779,  138775.49962929,   65306.1200317 ,\n",
       "          81188.38793502,  119049.30672534,   50357.35455559,\n",
       "         124319.71795135,   93789.33883472,  143791.4814151 ,\n",
       "          85706.95104175,  137973.33000307,   81188.38959035,\n",
       "         137180.37923834,  112062.84570928]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_measure(Y[:10],'closeness_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_st\n",
      "results_mm\n",
      "results_orig\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0.960280</td>\n",
       "      <td>0.074617</td>\n",
       "      <td>0.099535</td>\n",
       "      <td>0.222009</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>{'alpha': 1.0, 'l1_ratio': 1e-10}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.114549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200314</td>\n",
       "      <td>0.211972</td>\n",
       "      <td>0.159416</td>\n",
       "      <td>0.213522</td>\n",
       "      <td>0.071906</td>\n",
       "      <td>0.223375</td>\n",
       "      <td>0.292769</td>\n",
       "      <td>0.042227</td>\n",
       "      <td>0.056727</td>\n",
       "      <td>0.007479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>0.043082</td>\n",
       "      <td>0.035487</td>\n",
       "      <td>0.099137</td>\n",
       "      <td>0.215989</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>{'alpha': 0.001, 'l1_ratio': 0.1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220121</td>\n",
       "      <td>0.204022</td>\n",
       "      <td>0.137460</td>\n",
       "      <td>0.206447</td>\n",
       "      <td>0.062404</td>\n",
       "      <td>0.218484</td>\n",
       "      <td>0.034916</td>\n",
       "      <td>0.040237</td>\n",
       "      <td>0.053974</td>\n",
       "      <td>0.007995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>0.030158</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>0.071883</td>\n",
       "      <td>0.167947</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>{'alpha': 0.001, 'l1_ratio': 0.1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.080503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141166</td>\n",
       "      <td>0.157003</td>\n",
       "      <td>0.096394</td>\n",
       "      <td>0.160320</td>\n",
       "      <td>0.039925</td>\n",
       "      <td>0.171526</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.011803</td>\n",
       "      <td>0.034718</td>\n",
       "      <td>0.006702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  mean_score_time  mean_test_score  \\\n",
       "0          65       0.960280         0.074617         0.099535   \n",
       "0          42       0.043082         0.035487         0.099137   \n",
       "0          42       0.030158         0.016952         0.071883   \n",
       "\n",
       "   mean_train_score  param_alpha  param_l1_ratio  \\\n",
       "0          0.222009        1.000    1.000000e-10   \n",
       "0          0.215989        0.001    1.000000e-01   \n",
       "0          0.167947        0.001    1.000000e-01   \n",
       "\n",
       "                              params  rank_test_score  split0_test_score  \\\n",
       "0  {'alpha': 1.0, 'l1_ratio': 1e-10}                1           0.114549   \n",
       "0  {'alpha': 0.001, 'l1_ratio': 0.1}                1           0.101439   \n",
       "0  {'alpha': 0.001, 'l1_ratio': 0.1}                1           0.080503   \n",
       "\n",
       "        ...         split7_test_score  split7_train_score  split8_test_score  \\\n",
       "0       ...                  0.200314            0.211972           0.159416   \n",
       "0       ...                  0.220121            0.204022           0.137460   \n",
       "0       ...                  0.141166            0.157003           0.096394   \n",
       "\n",
       "   split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
       "0            0.213522           0.071906            0.223375      0.292769   \n",
       "0            0.206447           0.062404            0.218484      0.034916   \n",
       "0            0.160320           0.039925            0.171526      0.019841   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.042227        0.056727         0.007479  \n",
       "0        0.040237        0.053974         0.007995  \n",
       "0        0.011803        0.034718         0.006702  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mod = '/nmnt/x03-hdd/HCP/exper_elastic_roi_modularity/'\n",
    "res = []\n",
    "for name in os.listdir(path_mod):\n",
    "    print(name)\n",
    "    res += [pd.read_csv(path_mod + name)]\n",
    "\n",
    "a,b,c = res\n",
    "pd.concat([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exper_elastic_nodes_to_edge\n",
      "exper_elastic_roi_av_clust\n",
      "exper_elastic_roi_modularity\n",
      "exper_lasso_nodes_to_edge\n"
     ]
    }
   ],
   "source": [
    "for folder in sorted(os.listdir('/nmnt/x03-hdd/HCP/')):\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_st\n",
      "results_mm\n",
      "results_orig\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0.754846</td>\n",
       "      <td>0.052604</td>\n",
       "      <td>0.094861</td>\n",
       "      <td>0.209921</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>{'alpha': 1.0, 'l1_ratio': 1e-10}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.102915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068982</td>\n",
       "      <td>0.216837</td>\n",
       "      <td>0.163229</td>\n",
       "      <td>0.201709</td>\n",
       "      <td>0.071719</td>\n",
       "      <td>0.209211</td>\n",
       "      <td>0.275440</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.065204</td>\n",
       "      <td>0.007953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>0.087736</td>\n",
       "      <td>0.065240</td>\n",
       "      <td>0.104614</td>\n",
       "      <td>0.242428</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>8.000000e-01</td>\n",
       "      <td>{'alpha': 1e-05, 'l1_ratio': 0.8}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.249530</td>\n",
       "      <td>0.194282</td>\n",
       "      <td>0.233522</td>\n",
       "      <td>0.093978</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>0.089704</td>\n",
       "      <td>0.049073</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.009790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>0.100196</td>\n",
       "      <td>0.061864</td>\n",
       "      <td>0.109467</td>\n",
       "      <td>0.242805</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>6.000000e-01</td>\n",
       "      <td>{'alpha': 1e-05, 'l1_ratio': 0.6}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099047</td>\n",
       "      <td>0.249633</td>\n",
       "      <td>0.204443</td>\n",
       "      <td>0.233654</td>\n",
       "      <td>0.079501</td>\n",
       "      <td>0.244138</td>\n",
       "      <td>0.074694</td>\n",
       "      <td>0.055529</td>\n",
       "      <td>0.086233</td>\n",
       "      <td>0.008869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  mean_score_time  mean_test_score  \\\n",
       "0          65       0.754846         0.052604         0.094861   \n",
       "0          36       0.087736         0.065240         0.104614   \n",
       "0          34       0.100196         0.061864         0.109467   \n",
       "\n",
       "   mean_train_score  param_alpha  param_l1_ratio  \\\n",
       "0          0.209921      1.00000    1.000000e-10   \n",
       "0          0.242428      0.00001    8.000000e-01   \n",
       "0          0.242805      0.00001    6.000000e-01   \n",
       "\n",
       "                              params  rank_test_score  split0_test_score  \\\n",
       "0  {'alpha': 1.0, 'l1_ratio': 1e-10}                1           0.102915   \n",
       "0  {'alpha': 1e-05, 'l1_ratio': 0.8}                1           0.093794   \n",
       "0  {'alpha': 1e-05, 'l1_ratio': 0.6}                1           0.101388   \n",
       "\n",
       "        ...         split7_test_score  split7_train_score  split8_test_score  \\\n",
       "0       ...                  0.068982            0.216837           0.163229   \n",
       "0       ...                  0.096200            0.249530           0.194282   \n",
       "0       ...                  0.099047            0.249633           0.204443   \n",
       "\n",
       "   split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
       "0            0.201709           0.071719            0.209211      0.275440   \n",
       "0            0.233522           0.093978            0.242000      0.089704   \n",
       "0            0.233654           0.079501            0.244138      0.074694   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.031400        0.065204         0.007953  \n",
       "0        0.049073        0.089958         0.009790  \n",
       "0        0.055529        0.086233         0.008869  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_av = '/nmnt/x03-hdd/HCP/exper_elastic_roi_av_clust/'\n",
    "res = []\n",
    "for name in os.listdir(path_av):\n",
    "    print(name)\n",
    "    res += [pd.read_csv(path_av + name)]\n",
    "\n",
    "a,b,c = res\n",
    "pd.concat([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_lasso = '/nmnt/x03-hdd/HCP/exper_lasso_nodes_to_edge/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.156840</td>\n",
       "      <td>0.021280</td>\n",
       "      <td>-0.068455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_iter': 10, 'alpha': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.062698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025189</td>\n",
       "      <td>0.020281</td>\n",
       "      <td>0.150589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.172558</td>\n",
       "      <td>0.017087</td>\n",
       "      <td>-0.068455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_iter': 100, 'alpha': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.062698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.150589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.158157</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>-0.068455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.000</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_iter': 100, 'alpha': 70}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.062698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045682</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>0.150589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  mean_score_time  mean_test_score  \\\n",
       "0           0       0.156840         0.021280        -0.068455   \n",
       "0           0       0.172558         0.017087        -0.068455   \n",
       "0           0       0.158157         0.019119        -0.068455   \n",
       "\n",
       "   mean_train_score  param_alpha  param_max_iter  \\\n",
       "0               0.0        1.000              10   \n",
       "0               0.0        0.001             100   \n",
       "0               0.0       70.000             100   \n",
       "\n",
       "                              params  rank_test_score  split0_test_score  \\\n",
       "0       {'max_iter': 10, 'alpha': 1}                1          -0.062698   \n",
       "0  {'max_iter': 100, 'alpha': 0.001}                1          -0.062698   \n",
       "0     {'max_iter': 100, 'alpha': 70}                1          -0.062698   \n",
       "\n",
       "        ...         split7_test_score  split7_train_score  split8_test_score  \\\n",
       "0       ...                 -0.033085                 0.0          -0.009529   \n",
       "0       ...                 -0.033085                 0.0          -0.009529   \n",
       "0       ...                 -0.033085                 0.0          -0.009529   \n",
       "\n",
       "   split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
       "0                 0.0          -0.001007                 0.0      0.025189   \n",
       "0                 0.0          -0.001007                 0.0      0.024437   \n",
       "0                 0.0          -0.001007                 0.0      0.045682   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.020281        0.150589              0.0  \n",
       "0        0.008902        0.150589              0.0  \n",
       "0        0.008230        0.150589              0.0  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges_name = []\n",
    "edges_res = []\n",
    "for folder in sorted(os.listdir(path_lasso)):\n",
    "    edges_name += [folder]\n",
    "    tmp = []\n",
    "    for name in sorted(os.listdir(path_lasso + folder)):\n",
    "        tmp += [pd.read_csv(path_lasso + folder + '/'+name)]\n",
    "    a, b, c = tmp\n",
    "    d = pd.concat([a,b,c])\n",
    "    edges_res += [d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge[0,10]  max mean test score: -0.0273492131793\n",
      "edge[0,11]  max mean test score: -0.0273492131793\n",
      "edge[0,12]  max mean test score: -0.0273492131793\n",
      "edge[0,13]  max mean test score: -0.0273492131793\n",
      "edge[0,14]  max mean test score: -0.0273492131793\n",
      "edge[0,15]  max mean test score: -0.0273492131793\n",
      "edge[0,16]  max mean test score: -0.0273492131793\n",
      "edge[0,17]  max mean test score: -0.0273492131793\n",
      "edge[0,18]  max mean test score: -0.0273492131793\n",
      "edge[0,19]  max mean test score: -0.0273492131793\n",
      "edge[0,1]  max mean test score: -0.0273492131793\n",
      "edge[0,20]  max mean test score: -0.0273492131793\n",
      "edge[0,21]  max mean test score: -0.0273492131793\n",
      "edge[0,22]  max mean test score: -0.0273492131793\n",
      "edge[0,23]  max mean test score: -0.0273492131793\n",
      "edge[0,24]  max mean test score: -0.0273492131793\n",
      "edge[0,25]  max mean test score: -0.0273492131793\n",
      "edge[0,26]  max mean test score: -0.0273492131793\n",
      "edge[0,27]  max mean test score: -0.0273492131793\n",
      "edge[0,28]  max mean test score: -0.0273492131793\n",
      "edge[0,29]  max mean test score: -0.0273492131793\n",
      "edge[0,2]  max mean test score: -0.0273492131793\n",
      "edge[0,30]  max mean test score: -0.0273492131793\n",
      "edge[0,31]  max mean test score: -0.0273492131793\n",
      "edge[0,32]  max mean test score: -0.0273492131793\n",
      "edge[0,33]  max mean test score: -0.0273492131793\n",
      "edge[0,34]  max mean test score: -0.0273492131793\n",
      "edge[0,35]  max mean test score: -0.0273492131793\n",
      "edge[0,36]  max mean test score: -0.0273492131793\n",
      "edge[0,37]  max mean test score: -0.0273492131793\n",
      "edge[0,39]  max mean test score: -0.0273492131793\n",
      "edge[0,3]  max mean test score: -0.0273492131793\n",
      "edge[0,40]  max mean test score: -0.0273492131793\n",
      "edge[0,41]  max mean test score: -0.0273492131793\n",
      "edge[0,42]  max mean test score: -0.0273492131793\n",
      "edge[0,43]  max mean test score: -0.0273492131793\n",
      "edge[0,44]  max mean test score: -0.0273492131793\n",
      "edge[0,45]  max mean test score: -0.0273492131793\n",
      "edge[0,46]  max mean test score: -0.0273492131793\n",
      "edge[0,47]  max mean test score: -0.0273492131793\n",
      "edge[0,48]  max mean test score: -0.0273492131793\n",
      "edge[0,49]  max mean test score: -0.0273492131793\n",
      "edge[0,53]  max mean test score: -0.0273492131793\n",
      "edge[0,54]  max mean test score: -0.0273492131793\n",
      "edge[0,55]  max mean test score: -0.0273492131793\n",
      "edge[0,56]  max mean test score: -0.0273492131793\n",
      "edge[0,57]  max mean test score: -0.0273492131793\n",
      "edge[0,59]  max mean test score: -0.0273492131793\n",
      "edge[0,5]  max mean test score: -0.0273492131793\n",
      "edge[0,60]  max mean test score: -0.0273492131793\n",
      "edge[0,61]  max mean test score: -0.0273492131793\n",
      "edge[0,62]  max mean test score: -0.0273492131793\n",
      "edge[0,63]  max mean test score: -0.0273492131793\n",
      "edge[0,6]  max mean test score: -0.0273492131793\n",
      "edge[0,7]  max mean test score: -0.0273492131793\n",
      "edge[0,8]  max mean test score: -0.0273492131793\n",
      "edge[0,9]  max mean test score: -0.0273492131793\n",
      "edge[1,2]  max mean test score: -0.0273492131793\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(edges_res)):\n",
    "    print(edges_name[i], ' max mean test score:',max(edges_res[0].mean_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/nmnt/x03-hdd/HCP/exper_elastic_nodes_to_edge/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges_name = []\n",
    "edges_res = []\n",
    "for folder in sorted(os.listdir(path)):\n",
    "    edges_name += [folder]\n",
    "    tmp = []\n",
    "    for name in sorted(os.listdir(path + folder)):\n",
    "        tmp += [pd.read_csv(path + folder+ '/'+name)]\n",
    "    a, b, c = tmp\n",
    "    d = pd.concat([a,b,c])\n",
    "    edges_res += [d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge[0,10]  max mean test score: -0.0273492131793\n",
      "edge[0,11]  max mean test score: -0.0273492131793\n",
      "edge[0,12]  max mean test score: -0.0273492131793\n",
      "edge[0,13]  max mean test score: -0.0273492131793\n",
      "edge[0,14]  max mean test score: -0.0273492131793\n",
      "edge[0,15]  max mean test score: -0.0273492131793\n",
      "edge[0,16]  max mean test score: -0.0273492131793\n",
      "edge[0,17]  max mean test score: -0.0273492131793\n",
      "edge[0,18]  max mean test score: -0.0273492131793\n",
      "edge[0,19]  max mean test score: -0.0273492131793\n",
      "edge[0,1]  max mean test score: -0.0273492131793\n",
      "edge[0,20]  max mean test score: -0.0273492131793\n",
      "edge[0,21]  max mean test score: -0.0273492131793\n",
      "edge[0,22]  max mean test score: -0.0273492131793\n",
      "edge[0,23]  max mean test score: -0.0273492131793\n",
      "edge[0,24]  max mean test score: -0.0273492131793\n",
      "edge[0,25]  max mean test score: -0.0273492131793\n",
      "edge[0,26]  max mean test score: -0.0273492131793\n",
      "edge[0,27]  max mean test score: -0.0273492131793\n",
      "edge[0,28]  max mean test score: -0.0273492131793\n",
      "edge[0,29]  max mean test score: -0.0273492131793\n",
      "edge[0,2]  max mean test score: -0.0273492131793\n",
      "edge[0,30]  max mean test score: -0.0273492131793\n",
      "edge[0,31]  max mean test score: -0.0273492131793\n",
      "edge[0,32]  max mean test score: -0.0273492131793\n",
      "edge[0,33]  max mean test score: -0.0273492131793\n",
      "edge[0,34]  max mean test score: -0.0273492131793\n",
      "edge[0,35]  max mean test score: -0.0273492131793\n",
      "edge[0,36]  max mean test score: -0.0273492131793\n",
      "edge[0,37]  max mean test score: -0.0273492131793\n",
      "edge[0,39]  max mean test score: -0.0273492131793\n",
      "edge[0,3]  max mean test score: -0.0273492131793\n",
      "edge[0,40]  max mean test score: -0.0273492131793\n",
      "edge[0,41]  max mean test score: -0.0273492131793\n",
      "edge[0,42]  max mean test score: -0.0273492131793\n",
      "edge[0,43]  max mean test score: -0.0273492131793\n",
      "edge[0,44]  max mean test score: -0.0273492131793\n",
      "edge[0,45]  max mean test score: -0.0273492131793\n",
      "edge[0,46]  max mean test score: -0.0273492131793\n",
      "edge[0,47]  max mean test score: -0.0273492131793\n",
      "edge[0,48]  max mean test score: -0.0273492131793\n",
      "edge[0,49]  max mean test score: -0.0273492131793\n",
      "edge[0,53]  max mean test score: -0.0273492131793\n",
      "edge[0,54]  max mean test score: -0.0273492131793\n",
      "edge[0,55]  max mean test score: -0.0273492131793\n",
      "edge[0,56]  max mean test score: -0.0273492131793\n",
      "edge[0,57]  max mean test score: -0.0273492131793\n",
      "edge[0,59]  max mean test score: -0.0273492131793\n",
      "edge[0,5]  max mean test score: -0.0273492131793\n",
      "edge[0,60]  max mean test score: -0.0273492131793\n",
      "edge[0,61]  max mean test score: -0.0273492131793\n",
      "edge[0,62]  max mean test score: -0.0273492131793\n",
      "edge[0,63]  max mean test score: -0.0273492131793\n",
      "edge[0,67]  max mean test score: -0.0273492131793\n",
      "edge[0,6]  max mean test score: -0.0273492131793\n",
      "edge[0,7]  max mean test score: -0.0273492131793\n",
      "edge[0,8]  max mean test score: -0.0273492131793\n",
      "edge[0,9]  max mean test score: -0.0273492131793\n",
      "edge[1,2]  max mean test score: -0.0273492131793\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(edges_res)):\n",
    "    print(edges_name[i], ' max mean test score:',max(edges_res[0].mean_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.221419</td>\n",
       "      <td>0.014509</td>\n",
       "      <td>-0.068455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.6}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.062698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.150589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.237644</td>\n",
       "      <td>0.019884</td>\n",
       "      <td>-0.068455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 1.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.062698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029382</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>0.150589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.242651</td>\n",
       "      <td>0.052291</td>\n",
       "      <td>-0.068455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'alpha': 0.001, 'l1_ratio': 0.6}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.062698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037276</td>\n",
       "      <td>0.035787</td>\n",
       "      <td>0.150589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  mean_score_time  mean_test_score  \\\n",
       "0           0       0.221419         0.014509        -0.068455   \n",
       "0           0       0.237644         0.019884        -0.068455   \n",
       "0           2       0.242651         0.052291        -0.068455   \n",
       "\n",
       "   mean_train_score  param_alpha  param_l1_ratio  \\\n",
       "0               0.0      100.000             0.6   \n",
       "0               0.0        5.000             1.0   \n",
       "0               0.0        0.001             0.6   \n",
       "\n",
       "                              params  rank_test_score  split0_test_score  \\\n",
       "0    {'alpha': 100, 'l1_ratio': 0.6}                1          -0.062698   \n",
       "0      {'alpha': 5, 'l1_ratio': 1.0}                1          -0.062698   \n",
       "0  {'alpha': 0.001, 'l1_ratio': 0.6}                1          -0.062698   \n",
       "\n",
       "        ...         split7_test_score  split7_train_score  split8_test_score  \\\n",
       "0       ...                 -0.033085                 0.0          -0.009529   \n",
       "0       ...                 -0.033085                 0.0          -0.009529   \n",
       "0       ...                 -0.033085                 0.0          -0.009529   \n",
       "\n",
       "   split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
       "0                 0.0          -0.001007                 0.0      0.028889   \n",
       "0                 0.0          -0.001007                 0.0      0.029382   \n",
       "0                 0.0          -0.001007                 0.0      0.037276   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.004960        0.150589              0.0  \n",
       "0        0.009022        0.150589              0.0  \n",
       "0        0.035787        0.150589              0.0  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_dim_target = {\n",
    "                    'wdegree' : to_degree(Y, mode = 'weighted'),\n",
    "                    'clustering' : clustering(Y),\n",
    "                    'rich_club' : rich_cl(Y),\n",
    "                    'betweenness' : local_measure(Y,'betweenness_centrality'),\n",
    "                    'closeness' : local_measure(Y,'closeness_centrality'),\n",
    "                    'deg_cent': local_measure(Y,'degree_centrality'),\n",
    "                    'eigenvector' : local_measure(Y,'eigenvector_centrality')\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.from_numpy_array(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014013159102348027"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.average_clustering(G, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = nx.from_numpy_array(Y[88])\n",
    "rcv = nx.rich_club_coefficient(G, normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{65, 66, 67}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set(rcv.keys())\n",
    "b = set(range(68))\n",
    "b.difference(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66.393092105263165, 0.69897832730560117, 67, 64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(len_of), np.std(len_of), max(len_of), min(len_of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.013157894736842, 2.3247434553008186, 30, 14)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(len_of_unq), np.std(len_of_unq), max(len_of_unq), min(len_of_unq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([36]), 0.89037698412698407)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(rcv == rcv[36])[0], rcv[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.8 ms ± 10.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "part = community.best_partition(G)\n",
    "mod_score = community.modularity(part, G, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39773960340470504"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part = community.best_partition(G)\n",
    "mod_score = community.modularity(part, G, weight='weight')\n",
    "mod_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mod_score(Y):\n",
    "    mod_score = []\n",
    "    for one in Y:\n",
    "        G = nx.from_numpy_array(one)\n",
    "        part = community.best_partition(G)\n",
    "        mod_score += [community.modularity(part, G, weight='weight')]\n",
    "    return np.array(mod_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01401316,  0.01345343,  0.01595999,  0.01035505,  0.01052121,\n",
       "        0.01119473,  0.01344307,  0.00863294,  0.00881524,  0.01074107])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_clus(Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def av_clus(Y):\n",
    "    av_clus = []\n",
    "    for one in Y:\n",
    "        G = nx.from_numpy_array(one)\n",
    "        av_clus += [nx.average_clustering(G, weight='weight')]\n",
    "    return np.array(av_clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "66\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "add_keys = b.difference(a)\n",
    "for idx in add_keys:\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rich_cl(Y):\n",
    "    rich_club = []\n",
    "    for one in Y:\n",
    "        G = nx.from_numpy_array(one)\n",
    "        rcv = nx.rich_club_coefficient(G, normalized=False)\n",
    "        a = set(rcv.keys())\n",
    "        b = set(range(68))\n",
    "        add_keys = b.difference(a)\n",
    "        for idx in add_keys:\n",
    "            rcv[idx] = 0 \n",
    "        rich_club += [np.array(list(rcv.values()))]\n",
    "    return np.array(rich_club)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def local_measure(Y, name):\n",
    "    measure = []\n",
    "    for one in Y:\n",
    "        G = nx.from_numpy_array(one)\n",
    "        if name != 'degree_centrality':\n",
    "            measure+= [np.array(list(getattr(nx, name)(G, weight='weight').values()))]\n",
    "        else:\n",
    "            measure+= [np.array(list(getattr(nx, name)(G).values()))]\n",
    "    return np.array(measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_dim_target = {'modularity': mod_score(Y),\n",
    "                  'aver_clustering': av_clus(Y),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.eigenvector_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_degree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-f3dc3289201b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m multi_dim_target = {'degree' : to_degree(Y, mode = 'binary'), \n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0;34m'wdegree'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mto_degree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0;34m'clustering'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0;34m'rich_club'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrich_cl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0;34m'betweenness'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlocal_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'betweenness_centrality'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_degree' is not defined"
     ]
    }
   ],
   "source": [
    "multi_dim_target = {'degree' : to_degree(Y, mode = 'binary'), \n",
    "                    'wdegree' : to_degree(Y, mode = 'weighted'),\n",
    "                    'clustering':clustering(Y),\n",
    "                    'rich_club':rich_cl(Y),\n",
    "                    'betweenness':local_measure(Y,'betweenness_centrality'),\n",
    "                    'closeness':local_measure(Y,'closeness_centrality'),\n",
    "                    'deg_cent': local_measure(Y,'degree_centrality'),\n",
    "                    'eigenvector':local_measure(Y,'eigenvector_centrality')\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(idx_nodes.shape)\n",
    "for i in range(68):\n",
    "    for j in range(i+1,68):\n",
    "        if np.sum(Y[:,i,j]) != 0:\n",
    "            node1 = idx_nodes[i]\n",
    "            node2 = idx_nodes[j]\n",
    "            print(node1, node2)\n",
    "            print(i,j)\n",
    "\n",
    "            X = get_nodes_attribute(thinkness, log_jac, mesh_area, mean_labels, node1, node2)\n",
    "\n",
    "            elastic = ElasticNet()\n",
    "            StanS = StandardScaler()\n",
    "            MinM = MinMaxScaler()\n",
    "            cv = ShuffleSplit(test_size=0.2)\n",
    "            rg = RandomizedSearchCV(elastic, elastic_param, scoring = 'r2', \n",
    "                                    n_jobs=-1, cv = 10)\n",
    "\n",
    "            rg.fit(X, Y[:,i,j])\n",
    "            orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "            orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "            rg.fit(StanS.fit_transform(X), Y[:,i,j])\n",
    "            st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "            st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "            rg.fit(MinM.fit_transform(X), Y[:,i,j])\n",
    "            mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "            mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "            name_dir = 'exper_elastic_nodes_to_edge'\n",
    "            edge = '/edge[' + str(i) + ',' + str(j) + ']'\n",
    "            if not os.path.exists(path_res + name_dir):\n",
    "                os.mkdir(path_res + name_dir)\n",
    "\n",
    "            if not os.path.exists(path_res + name_dir + edge):\n",
    "                os.mkdir(path_res + name_dir + edge)\n",
    "            orig.to_csv(path_res + name_dir + edge +'/results_orig')\n",
    "            st.to_csv(path_res + name_dir + edge + '/results_st')\n",
    "            mm.to_csv(path_res + name_dir + edge + '/results_mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx_nodes = list(range(1,4)) + list(range(5,39)) + list(range(40,71))\n",
    "idx_nodes = np.array(idx_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_nodes[63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_nodes = list(range(1,4)) + list(range(5,39)) + list(range(40,70))\n",
    "for i in range(68):\n",
    "    for j in range(i+1,68):\n",
    "        if np.sum(Y[:,i,j]) != 0:\n",
    "            node1, node2 = idx_nodes[i], idx_nodes[j]\n",
    "            print(node1, node2)\n",
    "            print(i,j)\n",
    "            \n",
    "            X = get_nodes_attribute(thinkness, log_jac, mesh_area, mean_labels, node1, node2)\n",
    "\n",
    "               \n",
    "            lasso = Lasso()\n",
    "            StanS = StandardScaler()\n",
    "            MinM = MinMaxScaler()\n",
    "            cv = ShuffleSplit(test_size=0.2)\n",
    "            rg = RandomizedSearchCV(lasso, lasso_param, scoring = 'r2', \n",
    "                                    n_jobs=-1, cv = 10)\n",
    "\n",
    "            rg.fit(X, Y[:,i,j])\n",
    "            orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "            orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "            rg.fit(StanS.fit_transform(X), Y[:,i,j])\n",
    "            st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "            st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "            rg.fit(MinM.fit_transform(X), Y[:,i,j])\n",
    "            mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "            mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "\n",
    "            name_dir = 'exper_lasso_nodes_to_edge'\n",
    "            edge = '/edge[' + str(i) + ',' + str(j) + ']'\n",
    "            if not os.path.exists(path_res + name_dir):\n",
    "                os.mkdir(path_res + name_dir)\n",
    "\n",
    "            if not os.path.exists(path_res + name_dir + edge):\n",
    "                os.mkdir(path_res + name_dir + edge)\n",
    "                \n",
    "            orig.to_csv(path_res + name_dir + edge +'/results_orig')\n",
    "            st.to_csv(path_res + name_dir + edge + '/results_st')\n",
    "            mm.to_csv(path_res + name_dir + edge + '/results_mm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "PLSRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "from utils import get_nodes_attribute\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, ShuffleSplit\n",
    "\n",
    "\n",
    "\n",
    "path_data = \"../\"\n",
    "\n",
    "with open(path_data + \"mean_mesh_labels\", 'rb') as f:\n",
    "    mean_labels = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"normed_connectomes\", 'rb') as f:\n",
    "    Y = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_log_jac\", 'rb') as f:\n",
    "    log_jac = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_thinkness\", 'rb') as f:\n",
    "    thinkness = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_mesh_area\", 'rb') as f:\n",
    "    mesh_area = pickle.load(f)\n",
    "\n",
    "\n",
    "    \n",
    "thinkness = thinkness.reshape(789,-1)\n",
    "log_jac = log_jac.reshape(789,-1)\n",
    "mesh_area = mesh_area.reshape(789,-1)\n",
    "\n",
    "\n",
    "\n",
    "plsr_param = {'n_components':[2,3,5],\n",
    "              'max_iter':[10, 100,500, 1000]}\n",
    "\n",
    "cv = ShuffleSplit(test_size=0.2)\n",
    "\n",
    "\n",
    "for i in range(1,70):\n",
    "        for j in range(i+1,70):\n",
    "            if i!=4 and i!=39:\n",
    "                print(i,j)\n",
    "                if np.sum(Y[:,i,j]) != 0:\n",
    "                \n",
    "\n",
    "                    \n",
    "                    X = get_nodes_attribute(thinkness, log_jac, mesh_area, mean_labels, i, j)\n",
    "                    \n",
    "                    plsr = PLSRegression()\n",
    "                    StanS = StandardScaler()\n",
    "                    MinM = MinMaxScaler()\n",
    "                    cv = ShuffleSplit(test_size=0.2)\n",
    "                    rg = RandomizedSearchCV(plsr, plsr_param, scoring = 'r2', \n",
    "                                            n_jobs=1, cv = 10)\n",
    "                    \n",
    "                    rg.fit(X, Y[:,i,j])\n",
    "                    orig = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "                    orig = orig.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "                    \n",
    "                    rg.fit(StanS.fit_transform(X), Y[:,i,j])\n",
    "                    st = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "                    st = st.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "                    \n",
    "                    rg.fit(MinM.fit_transform(X), Y[:,i,j])\n",
    "                    mm = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "                    mm = mm.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "                    \n",
    "                    name_dir = 'exper_plsr_nodes_to_edge'\n",
    "                    edge = '/edge[' + str(i) + ',' + str(j) + ']'\n",
    "                    if not os.path.exists(name_dir):\n",
    "                        os.mkdir(name_dir)\n",
    "\n",
    "                    if not os.path.exists(name_dir + edge):\n",
    "                        os.mkdir(name_dir + edge)\n",
    "                    orig.to_csv(name_dir + edge +'/results_orig')\n",
    "                    st.to_csv(name_dir + edge + '/results_st')\n",
    "                    mm.to_csv(name_dir + edge + '/results_mm')\n",
    "                    break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_cmd_cobrain.py python some_script.py -c 8 -r 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "from parsimony.estimators import LinearRegressionL2SmoothedL1TV\n",
    "from parsimony.functions.nesterov.tv import linear_operator_from_mesh\n",
    "from parsimony.estimators import GridSearchKFoldRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data_load import load_meshes_coor_tria\n",
    "from utils import get_meshes_coord_tria, get_nodes_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_meshes = '../'\n",
    "\n",
    "mesh_coord, mesh_triangles = load_meshes_coor_tria(path_meshes)\n",
    "\n",
    "path_data = \"../\"\n",
    "\n",
    "with open(path_data + \"mean_mesh_labels\", 'rb') as f:\n",
    "    mean_labels = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"normed_connectomes\", 'rb') as f:\n",
    "    Y = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_log_jac\", 'rb') as f:\n",
    "    log_jac = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_thinkness\", 'rb') as f:\n",
    "    thinkness = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_mesh_area\", 'rb') as f:\n",
    "    mesh_area = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X\n",
    "st = StandardScaler()\n",
    "new_X = st.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thinkness =  StanS.fit_transform(thinkness)\n",
    "log_jac =  StanS.fit_transform(log_jac)\n",
    "mesh_area =  StanS.fit_transform(mesh_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StanS = StandardScaler()\n",
    "St_think =  StanS.fit_transform(thinkness)\n",
    "St_log_jac =  StanS.fit_transform(log_jac)\n",
    "St_mesh_area =  StanS.fit_transform(mesh_area)\n",
    "\n",
    "MinM = MinMaxScaler()\n",
    "MinM_think =  MinM.fit_transform(thinkness)\n",
    "MinM_log_jac =  MinM.fit_transform(log_jac)\n",
    "MinM_mesh_area =  MinM.fit_transform(mesh_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thinkness = thinkness.reshape(789,-1)\n",
    "log_jac = log_jac.reshape(789,-1)\n",
    "mesh_area = mesh_area.reshape(789,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid ={'l1': [1e-7, 1e-3, 0.1, 0.5, 1, 10, 100],\n",
    "    \n",
    "             'l2': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "\n",
    "             'tv': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "\n",
    "             'penalty_start': [0,10,100,1000,10000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = linear_operator_from_mesh(mesh_coord, mesh_triangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import parsimony.functions.nesterov.l1tv as l1tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_tria = get_meshes_coord_tria(mesh_triangles, mean_labels, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = linear_operator_from_mesh(mesh_coord, new_tria)\n",
    "B = l1tv.linear_operator_from_mesh(mesh_coord, new_tria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, ShuffleSplit\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso_param = {'alpha':[0.1, 1, 10,4000],\n",
    "              'max_iter':[10, 100, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = make_regression()\n",
    "cv = ShuffleSplit(test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(lasso, lasso_param, scoring=make_scorer(r2_score), cv = cv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rg = RandomizedSearchCV(lasso, lasso_param, scoring = make_scorer(r2_score), \n",
    "#                                             n_jobs=1, cv = cv, refit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rg = RandomizedSearchCV(lasso, lasso_param, scoring = {'MSE':make_scorer(mean_squared_error),\n",
    "#                                                        'AE':make_scorer(mean_absolute_error),\n",
    "#                                                        'r2':make_scorer(r2_score)}, \n",
    "#                                             n_jobs=1, cv = cv, refit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rg.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rg.best_params_, rg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('try')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,70):\n",
    "        for j in range(i+1,70):\n",
    "            if i!=4 and i!=39:\n",
    "                print(i,j)\n",
    "                if np.sum(Y[:,i,j]) != 0:\n",
    "                \n",
    "                    #new_tria = get_meshes_coord_tria(mesh_triangles, mean_labels, i, j)\n",
    "                    #A = linear_operator_from_mesh(mesh_coord, new_tria)\n",
    "                    #print(len(A))\n",
    "                    \n",
    "                    X = get_nodes_attribute(thinkness, log_jac, mesh_area, mean_labels, i, j)\n",
    "                    \n",
    "                    lasso = Lasso()\n",
    "                    cv = ShuffleSplit(test_size=0.2)\n",
    "                    rg = RandomizedSearchCV(lasso, lasso_param, scoring = make_scorer(r2_score), \n",
    "                                            n_jobs=1, cv = 10)\n",
    "                    \n",
    "                    rg.fit(X, Y[:,i,j])\n",
    "                    data = pd.DataFrame.from_dict(rg.cv_results_)\n",
    "                    data = data.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "                    \n",
    "\n",
    "                    \n",
    "                    name_dir = 'exper_lasso_nodes_to_edge'\n",
    "                    edge = '/edge[' + str(i) + ',' + str(j) + ']'\n",
    "                    if not os.path.exists(name_dir):\n",
    "                        os.mkdir(name_dir)\n",
    "\n",
    "                    if not os.path.exists(name_dir + edge):\n",
    "                        os.mkdir(name_dir + edge)\n",
    "                    data.to_csv(name_dir + edge +'/results')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_st = []\n",
    "best_params_st = []\n",
    "score_mm = []\n",
    "best_params_mm = []\n",
    "for i in range(1,70):\n",
    "        for j in range(i,70):\n",
    "            if i!=4 and i!=39:\n",
    "                if np.sum(y[:,i,j])! = 0:\n",
    "                \n",
    "                    new_tria = get_meshes_coord_tria(mesh_triangles, mean_labels, i, j)\n",
    "                    A = tv_helper.linear_operator_from_mesh(mesh_coord, new_tria)\n",
    "\n",
    "                    X = get_nodes_attribute(St_think, St_log_jac,St_mesh_area, mean_labels, i, j)\n",
    "                    tvenet_estimator = estimators.LinearRegressionL2SmoothedL1TV(l1=0., l2=0., tv=0., A = A)\n",
    "                    GridSearch = GridSearchKFoldRegression(tvenet_estimator, param_grid, maximise=False, K = 10)\n",
    "                    GridSearch.fit(X, y[:,i, j])\n",
    "                    score_st += [GridSearch._best_results]\n",
    "                    best_params_st += [GridSearch._best_params]\n",
    "\n",
    "\n",
    "\n",
    "                    X = get_nodes_attribute(MinM_think, MinM_log_jac, MinM_mesh_area, mean_labels, i, j)\n",
    "\n",
    "                    tvenet_estimator = estimators.LinearRegressionL2SmoothedL1TV(l1=0.1, l2=0.1, tv=0.1, A = A)\n",
    "                    GridSearch = GridSearchKFoldRegression(tvenet_estimator, param_grid,maximise=False, K = 10)\n",
    "                    GridSearch.fit(X, y[:,i, j])\n",
    "                    score_mm += [GridSearch._best_results]\n",
    "                    best_params_mm += [GridSearch._best_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path_meshes = '/home/bgutman/datasets/HCP/'\n",
    "\n",
    "# mesh_coord, mesh_triangles = load_meshes_coor_tria(path_meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path_data = \"/cobrain/groups/ml_group/data/HCP/cleaned_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path_data + \"normed_connectomes\", 'rb') as f:\n",
    "    Y = pickle.load(f)\n",
    "with open(path_data + \"subjects_log_jac\", 'rb') as f:\n",
    "    log_jac = pickle.load(f)\n",
    "with open(path_data + \"subjects_thinkness\", 'rb') as f:\n",
    "    thinkness = pickle.load(f)\n",
    "with open(path_data + \"subjects_mesh_area\", 'rb') as f:\n",
    "    mesh_area = pickle.load(f)\n",
    "with open(path_data + \"subjects_roi_thinkness\", 'rb') as f:\n",
    "    roi_thinkness = pickle.load(f)\n",
    "with open(path_data + \"subjects_roi_volume\", 'rb') as f:\n",
    "    roi_volume = pickle.load(f)\n",
    "with open(path_data + \"mean_mesh_labels\", 'rb') as f:\n",
    "    mean_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid ={'l1': [1e-7, 1e-3, 0.1, 0.5, 1, 10, 100],\n",
    "    \n",
    "             'l2': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "\n",
    "             'tv': [1e-7, 1e-3, 0.1,0.5, 1, 10, 100],\n",
    "\n",
    "             'penalty_start': [0,10,100,1000,10000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StanS = StandardScaler()\n",
    "St_think =  StanS.fit_transform(thinkness)\n",
    "St_log_jac =  StanS.fit_transform(log_jac)\n",
    "St_mesh_area =  StanS.fit_transform(mesh_area)\n",
    "\n",
    "MinM = MinMaxScaler()\n",
    "MinM_think =  MinM.fit_transform(thinkness)\n",
    "MinM_log_jac =  MinM.fit_transform(log_jac)\n",
    "MinM_mesh_area =  MinM.fit_transform(mesh_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_st = []\n",
    "best_params_st = []\n",
    "score_mm = []\n",
    "best_params_mm = []\n",
    "for i in range(1,70):\n",
    "        for j in range(i,70):\n",
    "            if i!=4 and i!=39:\n",
    "                if np.sum(y[:,i,j])! = 0:\n",
    "                \n",
    "                    new_tria = get_meshes_coord_tria(mesh_triangles, mean_labels, i, j)\n",
    "                    A = tv_helper.linear_operator_from_mesh(mesh_coord, new_tria)\n",
    "\n",
    "                    X = get_nodes_attribute(St_think, St_log_jac,St_mesh_area, mean_labels, i, j)\n",
    "                    tvenet_estimator = estimators.LinearRegressionL2SmoothedL1TV(l1=0., l2=0., tv=0., A = A)\n",
    "                    GridSearch = GridSearchKFoldRegression(tvenet_estimator, param_grid, maximise=False, K = 10)\n",
    "                    GridSearch.fit(X, y[:,i, j])\n",
    "                    score_st += [GridSearch._best_results]\n",
    "                    best_params_st += [GridSearch._best_params]\n",
    "\n",
    "\n",
    "\n",
    "                    X = get_nodes_attribute(MinM_think, MinM_log_jac, MinM_mesh_area, mean_labels, i, j)\n",
    "\n",
    "                    tvenet_estimator = estimators.LinearRegressionL2SmoothedL1TV(l1=0.1, l2=0.1, tv=0.1, A = A)\n",
    "                    GridSearch = GridSearchKFoldRegression(tvenet_estimator, param_grid,maximise=False, K = 10)\n",
    "                    GridSearch.fit(X, y[:,i, j])\n",
    "                    score_mm += [GridSearch._best_results]\n",
    "                    best_params_mm += [GridSearch._best_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_st = np.array(score_st)\n",
    "best_params_st = np.array(best_params_st)\n",
    "score_mm = np.array(score_mm)\n",
    "best_params_mm = np.array(best_params_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_dir = 'exper_tv_nodes_to_edge'\n",
    "edge = '/edge[' + str(i) + ',' + str(j) + ']'\n",
    "if !os.path.exists(name_dir):\n",
    "    os.mkdir(name_dir)\n",
    "    \n",
    "    if !os.path.exists(name_dir + edge):\n",
    "        os.mkdir(name_dir + edge)\n",
    "\n",
    "with open(name_dir + edge + '/score_st.pkl', 'wb') as f:\n",
    "    pickle.dump(score_st,f)\n",
    "with open(name_dir + edge + '/score_mm.pkl', 'wb') as f:\n",
    "    pickle.dump(score_mm,f)\n",
    "with open(name_dir + edge + '/best_params_st.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params_st,f)\n",
    "with open(name_dir + edge + '/best_params_mm.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params_mm,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
