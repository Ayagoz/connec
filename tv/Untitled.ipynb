{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meshes coordinates shape:  (327684, 3)\n",
      "Number of triangles of meshes:  (655360, 3)\n",
      "(6, 789, 68)\n",
      "(68,)\n",
      "(49765, 3)\n",
      "I am here\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from flexible_linear import FlexibleLinearRegression\n",
    "\n",
    "from tv_utils import CustomTVReg, integration_mesh_to_tria, get_meshes_coord_tria, get_nodes_attribute\n",
    "from data_load import load_meshes_coor_tria\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "path_data = \"/cobrain/groups/ml_group/data/HCP/cleaned_data/\"\n",
    "\n",
    "with open(path_data + \"mean_mesh_labels\", 'rb') as f:\n",
    "    mean_labels = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(path_data + \"subjects_log_jac\", 'rb') as f:\n",
    "    log_jac = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_thinkness\", 'rb') as f:\n",
    "    thinkness = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_mesh_area\", 'rb') as f:\n",
    "    mesh_area = pickle.load(f)\n",
    "\n",
    "path_tria= \"/cobrain/groups/ml_group/data/HCP/HCP/\"\n",
    "coord, tria = load_meshes_coor_tria(path_tria)\n",
    "\n",
    "del coord\n",
    "\n",
    "targets_name = ['clustering', 'rich_club', 'betweenness', 'closeness',  'degree_centrality', 'eigenvector']\n",
    "\n",
    "targets_data = []\n",
    "for name in targets_name:\n",
    "    with open(path_data + name, 'rb') as f:\n",
    "        targets_data  += [pickle.load(f)]\n",
    "\n",
    "print(np.array(targets_data).shape)\n",
    "\n",
    "\n",
    "params = {'C':np.linspace(1e-10, 0.1, 5),\n",
    "         'cost_func': ['l2', 'l1', 'japanese']}\n",
    "\n",
    "\n",
    "path_res = '/home/ayagoz/connec/results/tv/'\n",
    "if not os.path.exists(path_res + 'node_to_node'):\n",
    "    os.mkdir(path_res + 'node_to_node')\n",
    "path_res += 'node_to_node/'\n",
    "\n",
    "thinkness = thinkness.reshape(789,-1)\n",
    "log_jac = log_jac.reshape(789,-1)\n",
    "mesh_area = mesh_area.reshape(789,-1)\n",
    "\n",
    "idx_nodes = list(range(1,4)) + list(range(5,39)) + list(range(40,71))\n",
    "idx_nodes = np.array(idx_nodes)\n",
    "print(idx_nodes.shape)\n",
    "X = []\n",
    "triangles = []\n",
    "for i in range(68):\n",
    "    node1 = idx_nodes[i]\n",
    "    node1_tria = get_meshes_coord_tria(tria, mean_labels, i)\n",
    "    print(np.array(node1_tria).shape)\n",
    "    triangles += [node1_tria] \n",
    "    T = integration_mesh_to_tria(node1_tria, thinkness)\n",
    "    L = integration_mesh_to_tria(node1_tria, log_jac)\n",
    "    M = integration_mesh_to_tria(node1_tria, mesh_area)\n",
    "    X += [[T,L,M]]\n",
    "    \n",
    "print('I am here')\n",
    "\n",
    "\n",
    "name = ['think/', 'log_jac/', 'mesh_area/']\n",
    "params = {'C':[3*1e-10, 1e-8, 1e-5, 1e-3, 0.1, 1, 10],\n",
    "         'cost_func': ['l2','l1', 'japanese']}\n",
    "\n",
    "\n",
    "def main_worker(i):\n",
    "    node1 = idx_nodes[i]\n",
    "    print(node1)\n",
    "    custom_tvl1 = CustomTVReg(data = triangles[i], mode_reg= 'l1')\n",
    "    custom_tvl2 = CustomTVReg(data = triangles[i], mode_reg= 'l2')\n",
    "\n",
    "    flexl1 = FlexibleLinearRegression(C=1e-8, reg_cost_func=custom_tvl1.tv_normed_cost_func)\n",
    "    flexl2 = FlexibleLinearRegression(C=1e-8, reg_cost_func=custom_tvl2.tv_normed_cost_func)\n",
    "    grl1 = GridSearchCV(flexl1, param_grid=params, n_jobs=1, scoring='r2', cv = 3)\n",
    "    grl2 = GridSearchCV(flexl1, param_grid=params, n_jobs=1, scoring='r2', cv = 3)\n",
    "\n",
    "    for folder in name:\n",
    "        if not os.path.exists(path_res + folder):\n",
    "            os.mkdir(path_res + folder)\n",
    "\n",
    "    print(X[i][0].shape, target[:,i].shape)\n",
    "\n",
    "\n",
    "\n",
    "    for k in range(3):\n",
    "\n",
    "        grl1.fit(X[i][k], target[:,i])\n",
    "        grl2.fit(X[i][k], target[:,i])\n",
    "        res_l1 = pd.DataFrame.from_dict(grl1.cv_results_)\n",
    "        res_l1 = res_l1.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "        res_l1.to_csv(path_res + name[j] + 'tv_l1')\n",
    "\n",
    "        res_l2 = pd.DataFrame.from_dict(grl2.cv_results_)\n",
    "        res_l2 = res_l2.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "        res_l2.to_csv(path_res + name[j] + 'tv_l2')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for j, target in enumerate(targets_data):\n",
    "    print(targets_name[j])\n",
    "    print(target.shape)\n",
    "    Parallel(n_jobs=1)(delayed(main_worker)(i) for i in range(68))\n",
    "    print('Finished work for ' + targets_name[j])\n",
    "print('I finished all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meshes coordinates shape:  (327684, 3)\n",
      "Number of triangles of meshes:  (655360, 3)\n",
      "(6, 789, 68)\n",
      "(68,)\n",
      "(49765, 3)\n",
      "I am here\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from flexible_linear import FlexibleLinearRegression\n",
    "\n",
    "from tv_utils import CustomTVReg, integration_mesh_to_tria, get_meshes_coord_tria, get_nodes_attribute\n",
    "from data_load import load_meshes_coor_tria\n",
    "\n",
    "path_data = \"/cobrain/groups/ml_group/data/HCP/cleaned_data/\"\n",
    "\n",
    "with open(path_data + \"mean_mesh_labels\", 'rb') as f:\n",
    "    mean_labels = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(path_data + \"subjects_log_jac\", 'rb') as f:\n",
    "    log_jac = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_thinkness\", 'rb') as f:\n",
    "    thinkness = pickle.load(f)\n",
    "\n",
    "with open(path_data + \"subjects_mesh_area\", 'rb') as f:\n",
    "    mesh_area = pickle.load(f)\n",
    "\n",
    "path_tria= \"/cobrain/groups/ml_group/data/HCP/HCP/\"\n",
    "coord, tria = load_meshes_coor_tria(path_tria)\n",
    "\n",
    "del coord\n",
    "\n",
    "targets_name = ['clustering', 'rich_club', 'betweenness', 'closeness',  'degree_centrality', 'eigenvector']\n",
    "\n",
    "targets_data = []\n",
    "for name in targets_name:\n",
    "    with open(path_data + name, 'rb') as f:\n",
    "        targets_data  += [pickle.load(f)]\n",
    "\n",
    "print(np.array(targets_data).shape)\n",
    "\n",
    "\n",
    "params = {'C':np.linspace(1e-10, 0.1, 5),\n",
    "         'cost_func': ['l2', 'l1', 'japanese']}\n",
    "\n",
    "\n",
    "path_res = '/home/ayagoz/connec/results/tv/'\n",
    "if not os.path.exists(path_res + 'node_to_node'):\n",
    "    os.mkdir(path_res + 'node_to_node')\n",
    "path_res += 'node_to_node/'\n",
    "\n",
    "thinkness = thinkness.reshape(789,-1)\n",
    "log_jac = log_jac.reshape(789,-1)\n",
    "mesh_area = mesh_area.reshape(789,-1)\n",
    "\n",
    "idx_nodes = list(range(1,4)) + list(range(5,39)) + list(range(40,71))\n",
    "idx_nodes = np.array(idx_nodes)\n",
    "print(idx_nodes.shape)\n",
    "X = []\n",
    "triangles = []\n",
    "for i in range(68):\n",
    "    node1 = idx_nodes[i]\n",
    "    node1_tria = get_meshes_coord_tria(tria, mean_labels, i)\n",
    "    print(np.array(node1_tria).shape)\n",
    "    triangles += [node1_tria] \n",
    "    T = integration_mesh_to_tria(node1_tria, thinkness)\n",
    "    L = integration_mesh_to_tria(node1_tria, log_jac)\n",
    "    M = integration_mesh_to_tria(node1_tria, mesh_area)\n",
    "    X += [[T,L,M]]\n",
    "    break\n",
    "print('I am here')\n",
    "\n",
    "\n",
    "name = ['think/', 'log_jac/', 'mesh_area/']\n",
    "params = {'C':[1e-8],\n",
    "         'cost_func': ['l2',]}\n",
    "for j, target in enumerate(targets_data):\n",
    "    print(targets_name[j])\n",
    "    print(target.shape)\n",
    "    for i in range(68):\n",
    "        \n",
    "        \n",
    "        node1 = idx_nodes[i]\n",
    "        print(node1)\n",
    "        custom_tvl1 = CustomTVReg(data = triangles[i], mode_reg= 'l1')#triangles[i]\n",
    "        custom_tvl2 = CustomTVReg(data = triangles[i], mode_reg= 'l2')\n",
    "        \n",
    "        flexl1 = FlexibleLinearRegression(C=1e-8, reg_cost_func=custom_tvl1.tv_normed_cost_func)\n",
    "        flexl2 = FlexibleLinearRegression(C=1e-8, reg_cost_func=custom_tvl2.tv_normed_cost_func, n_)\n",
    "        grl1 = GridSearchCV(flexl1, param_grid=params, scoring='r2', cv = 3)\n",
    "        grl2 = GridSearchCV(flexl1, param_grid=params, scoring='r2', cv = 3)\n",
    "        \n",
    "        for folder in name:\n",
    "            if not os.path.exists(path_res + folder):\n",
    "                os.mkdir(path_res + folder)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for k in range(3):\n",
    "            \n",
    "            grl1.fit(X[i][k], target[:,i])\n",
    "            \n",
    "            res_think = pd.DataFrame.from_dict(grl1.cv_results_)\n",
    "            res_think = res_think.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "            res_think.to_csv(path_res + name[j] + 'tv_l1')\n",
    "        \n",
    "        for k in range(3):\n",
    "            grl2.fit(X[i][k], target[:,i])\n",
    "            res_think = pd.DataFrame.from_dict(grl1.cv_results_)\n",
    "            res_think = res_think.sort_values(by = 'rank_test_score').iloc[:1]\n",
    "            res_think.to_csv(path_res + name[j] + 'tv_l2')\n",
    "    print('Finished work for ' + targets_name[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
